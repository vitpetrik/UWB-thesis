[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fusion of UWB-Based Distance Sensors with a Visual Relative Localization System",
    "section": "",
    "text": "1 Introduction\nIn recent years, the use of unmanned aerial vehicles (UAVs) has been rapidly growing due to their versatility and wide range of applications, from aerial photography and surveillance to delivery services 1 and search and rescue operations [1]. The problem of relative localization in UAV swarms is a critical challenge for enabling cooperative behavior and avoiding collisions.\nTo address this problem, a novel system is proposed in this thesis that combines computer vision and ultra-wideband (UWB) technology for direction and range measurements, respectively. By fusing these measurements using a Kalman filter, the relative positions and orientations of UAVs can be estimated with high accuracy, even in GNSS-denied environments such as undergrounds, buildings or caves [1]. This approach has a significant advantage over existing methods, which often rely on GNSS [2] or motion capture 2 and are therefore limited in their ability to operate in challenging environments or without additional infrastructure onsite.\nThe research question for this thesis is: How can an effective relative localization system for UAV swarms be designed and implemented using computer vision and UWB technology, and how well does it perform in real-world scenarios? Firstly, a review of the existing literature on relative localization and multi-robot systems will be conducted. Secondly, the proposed system and its key components, including the computer vision algorithms for direction estimation and the UWB hardware for range measurement, will be presented. Finally, the performance of the system will be evaluated through a series of experiments in both simulated and real-world environments and compared with existing approaches.\nBy developing and testing this system, a contribution will be made to the growing body of research on multi-robot systems and pave the way for new applications of UAV swarms in challenging environments."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Fusion of UWB-Based Distance Sensors with a Visual Relative Localization System",
    "section": "",
    "text": "Blood and packages delivery https://www.flyzipline.com↩︎\nMotion capture OptiTrack https://optitrack.com↩︎"
  },
  {
    "objectID": "chapters/2_uvdar.html",
    "href": "chapters/2_uvdar.html",
    "title": "2  Ultra-violet Detection and Ranging",
    "section": "",
    "text": "The Ultra-violet Direction and Ranging (UVDAR) is a system for relative localization based on computer vision. The system was developed by the Multi-robot system group at CTU [2]. It consists of two parts, active UV LED markers and industrial grade camera with UV bandpass filter and fisheye lens. This allows the system to exactly recognize active markers from the background and work even in a pitch-black environment. This effect can be seen in image 2.1.\n\n\n\nFigure 2.1: Image from UV camera.\n\n\n\n\n\nFigure 2.2: UVDAR processing data flow. [1]\n\n\n\n\n\n\n\n1. V. Walter, N.Staub, M. Saska, and A. Franchi. 2018. Mutual localization of UAVs based on blinking ultraviolet markers and 3D time-position hough transform. In 14th IEEE international conference on automation science and engineering (CASE 2018).\n\n\n2. V. Walter, M. Saska, and A. Franchi. 2018. Fast mutual relative localization of uavs using ultraviolet led markers. In 2018 international conference on unmanned aircraft system (ICUAS 2018).\n\n\n\n\n\n\n\n  \n\n\n\n\nBibliography\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nConclusion\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nImplementation on MAV\n\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nKalman filters\n\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nSimulations and real-world experiments\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-wide band\n\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2023\n\n\nVit Petrik\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "chapters/3_uwb.html#mac-layer",
    "href": "chapters/3_uwb.html#mac-layer",
    "title": "3  Ultra-wide band",
    "section": "3.1 MAC layer",
    "text": "3.1 MAC layer\nIEEE 802.15.4 describes the MAC layer for low-rate wireless personal networks, including UWB. The MAC layer is responsible for coordinating access to the shared wireless channel, managing network associations and disassociations, and providing security and reliability features. The MAC layer inserts a MAC header and a MAC footer before and after a network-layer frame, respectively. The MAC header contains information such as frame type, source and destination addresses, sequence number, and security parameters. The MAC footer contains a CRC check. The IEEE 802.15.4 MAC layer supports two modes of operation: beacon-enabled and non-beacon-enabled. In beacon-enabled mode, a coordinator device periodically broadcasts beacons to synchronize the devices in its network and allocate contention-free periods for data transmission. In non-beacon-enabled mode, devices use a slotted or unslotted carrier sense multiple access with collision avoidance (CSMA-CA) mechanism to access the channel. The exact layout of MAC frame format is described in Table [tbl-mac-frame].\n‘\n\nwidth=\n\n|ccccccc|c|c| & & & & & & 0/5/6/10/14 & variable & 2\n& & & & & & & &\n& & & & &\n&\n\n\n\n\n(a) MAC frame format.\n\n\nMAC\n\n\nPayload\n\n\n\n\n\n\nTable 3.1: ?(caption)\n\n\n& MFR"
  },
  {
    "objectID": "chapters/3_uwb.html#physical-layer",
    "href": "chapters/3_uwb.html#physical-layer",
    "title": "3  Ultra-wide band",
    "section": "3.2 Physical Layer",
    "text": "3.2 Physical Layer\nThe physical (PHY) layer of UWB was described in IEEE 802.15.4-2011 [1] as UWB PHY. Later in IEEE 802.15.4-2015 [2] the PHY was named as High repetition pulse (HRP) UWB PHY. This decision was made due to the introduction of Low repetition pulse (LRP) UWB PHY. Only the HRP UWB PHY will be discussed. The standard defines three operation bands:\n\nsub-gigahertz band consisting of single a channel spectrum from 249.6 MHz to 749.6 MHz.\nLow band with spectrum from 3.1 GHz to 4.8 GHz.\nHigh band with spectrum from 6 GHz to 10.6 GHz.\n\n\n\n\nFigure 3.2: Data flow according to [1].\n\n\nIt uses an impulse radio signaling scheme with band-limited pulses and supports high data rates and precision ranging applications. It also uses a combination of burst position modulation (BPM) and binary phase-shift keying (BPSK) to modulate symbols. The overview of the physical layer is expressed in figure 3.2.\n\nPPDU format\nEach physical layer protocol data unit (PPDU) consists of a preamble, PHY header, and the data itself. The process of encoding the whole PPDU can be seen in figure 3.3.\nReed-Solomon encoding is used to encode the physical service data unit (PSDU) of the HRP UWB PHY. It adds redundant symbols to the original message symbols to form a codeword that can be decoded using polynomial interpolation or factorization techniques. Reed-Solomon encoding improves the error-correction performance of the HRP UWB PHY and enables it to handle burst errors or random errors that may occur in the wireless channel 4.\nConvolutional encoding is used to encode the PSDU of the HRP UWB PHY after Reed-Solomon encoding. It uses a finite state machine with memory cells to generate output bits based on the current and previous input bits. It adds parity bits to the original information bits to form a codeword that can be decoded using Viterbi algorithm or other sequential decoding techniques. Convolutional encoding improves the error-correction performance of the HRP UWB PHY and enables it to handle noisy or fading channels.\n\n\n\nFigure 3.3: PPDU encoding process [1].\n\n\nA preamble in HRP UWB PHY is a sequence of known bits sent at the beginning of each frame. It is used for frame synchronization, channel estimation, and ranging measurements. It consists of two parts: a synchronization header (SHR) 3.4 and a physical layer header (PHR) 3.5.\nThe SHR contains a preamble symbol (SYNC) and a start-of-frame delimiter (SFD). The SFD is a fixed sequence of pulses that indicates the start of a frame. The PS is a burst of UWB pulses that can be modulated by burst position modulation (BPM) or binary phase-shift keying (BPSK). The preamble symbol repetitions (PSR) define the number of repeated sequences, ranging from 16 to 4,096 repetitions.\n\n\n\nFigure 3.4: SHR field structure. [2]\n\n\nThe PHR contains information about the data to be received, including the length of the data and the data rate used to transmit the data. It also contains additional information elements to facilitate ranging information exchange\n\n\n\nFigure 3.5: PHR field structure. [2]\n\n\n\n\n3.2.1 Symbol structure\nA symbol 3.7 is the basic unit of information in HWP UWB PHY. It consists of a short burst of UWB pulses that lasts for 2 ns and occupies a bandwidth of 0.5-1.3 GHz. The burst can be placed in one of the two possible burst intervals, and its phase can be inverted or not. These two choices allow each symbol to carry two bits of information using burst position modulation (BPM) and binary phase-shift keying (BPSK), a example of the modulation can be found in figure 3.6.\n\n\n\n\n\nFigure 3.6: Example of BPS-BPSK modulation,\n\n\n\n\nBurst hopping position is a parameter that determines the time position of the UWB pulses within a burst interval. Scrambling code is a pseudo-random sequence that is applied to the data bits before modulation. It is used to randomize the data bits and reduce the peak-to-average power ratio (PAPR) of the UWB pulses.\n\n\n\nFigure 3.7: Symbol stucture. [2]\n\n\nIEEE defines the reference pulse as a root-raised cosine pulse with roll-off factor \\(\\beta = 0.5\\) 3.3.\n\\[         \nr(t) = \\frac{4 \\beta}{\\pi \\sqrt{T_p}} \\frac{\\cos{[(1+ \\beta) \\pi t / T_p]} + \\frac{\\sin{[(1 - \\beta) \\pi t / T_p}]}{4 \\beta(t / T_p)}}{1-(4 \\beta t /  T_p)^2}\n\\tag{3.3}\\]\nParameter \\(T_p\\) stands for duration of the pulse. The duration is defined for each channel by table 3.2.\n\n\nTable 3.2: Reference pulse duration for each channel. [1]\n\n\n\n\n\n\n\nChannel number\nPulse duration \\(T_p\\) (ns)\nMain lobe width \\(T_w\\) (ns)\n\n\n\n\n{0:3, 5:6, 8:10, 12:14}\n2.00\n0.5\n\n\n7\n0.92\n0.2\n\n\n{4, 11}\n0.75\n0.2\n\n\n15\n0.74\n0.2\n\n\n\n\nFigure 3.8 further illustrates a waveform of the pulse. However an actual hardware system cannot fully realize the shape of the reference pulse. Therefore IEEE 802.15.4 constrains transmitted pulse \\(p(t)\\) by a cross-correlation function 3.4. For PHY to be IEEE compliant the main lobe of the transmitted pulse must have a magnitude of cross correlation \\(|\\phi(\\tau)|\\) at least 0.8, and the magnitude of sidelobes must not be greater than 0.3.\n\\[\n    \\mathrm{\\phi}(\\tau) = \\frac{1}{\\sqrt{E_r E_p}} Re \\int^{\\infty}_{-\\infty} \\mathrm{r}(t) \\mathrm{p}(t - \\tau) \\mathrm{dt}\n\\tag{3.4}\\] Where:\n\\[\\begin{aligned}\n    E_r &= \\text{energy of r(t)} \\\\\n    E_p &= \\text{energy of p(t)} \\\\\n\\end{aligned}\\]\n\n\n\n\n\nFigure 3.8: Reference pulse of UWB radio."
  },
  {
    "objectID": "chapters/3_uwb.html#ranging-techniques",
    "href": "chapters/3_uwb.html#ranging-techniques",
    "title": "3  Ultra-wide band",
    "section": "3.3 Ranging techniques",
    "text": "3.3 Ranging techniques\n\nTime Difference of Arrival\n\n\nTwo way ranging\n\n\n\nFigure 3.9: Double sided two way ranging\n\n\n\n\nAngle of Arrival\n\n\n\n\n\n1. 2011. IEEE standard for local and metropolitan area networks–part 15.4: Low-rate wireless personal area networks (LR-WPANs). IEEE Std 802.15.4-2011 (Revision of IEEE Std 802.15.4-2006): 1–314. https://doi.org/10.1109/IEEESTD.2011.6012487\n\n\n2. 2016. IEEE standard for low-rate wireless networks. IEEE Std 802.15.4-2015 (Revision of IEEE Std 802.15.4-2011): 1–709. https://doi.org/10.1109/IEEESTD.2016.7460875"
  },
  {
    "objectID": "chapters/3_uwb.html#footnotes",
    "href": "chapters/3_uwb.html#footnotes",
    "title": "3  Ultra-wide band",
    "section": "",
    "text": "Apple AirTag https://www.apple.com/airtag/↩︎\nSiemens RTLS https://www.siemens.com/global/en/products/automation/industrial-identification/simatic-rtls.html/↩︎\nSewio real-time location system https://www.sewio.net/↩︎\nMathworks HRP UWB IEEE 802.15.4a/z Waveform Generation https://www.mathworks.com/help/comm/ug/hrp-uwb-ieee-802.15.4az-waveform-generation.html↩︎"
  },
  {
    "objectID": "chapters/4_kalman.html#linear-kalman-filter",
    "href": "chapters/4_kalman.html#linear-kalman-filter",
    "title": "4  Kalman filters",
    "section": "4.1 Linear Kalman filter",
    "text": "4.1 Linear Kalman filter"
  },
  {
    "objectID": "chapters/4_kalman.html#unscented-kalman-filter",
    "href": "chapters/4_kalman.html#unscented-kalman-filter",
    "title": "4  Kalman filters",
    "section": "4.2 Unscented Kalman filter",
    "text": "4.2 Unscented Kalman filter"
  },
  {
    "objectID": "chapters/5_implementation.html",
    "href": "chapters/5_implementation.html",
    "title": "5  Implementation on MAV",
    "section": "",
    "text": "Bibliography\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nConclusion\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nKalman filters\n\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nSimulations and real-world experiments\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-violet Detection and Ranging\n\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-wide band\n\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2023\n\n\nVit Petrik\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "chapters/6_experiments.html#results",
    "href": "chapters/6_experiments.html#results",
    "title": "6  Simulations and real-world experiments",
    "section": "6.1 Results",
    "text": "6.1 Results\nAll proposed experiments were successfully conducted. The first experiment [Figure 6.2] showed that the UWB measurements are indeed precise and do not express any signs of nonlinearity. The maximum range of 120 m was reached by UWB, however, the measurements at the far end are not reliable and often drops out. This can be seen as straight lines in Figure 6.2. Somehow cite this [1]\n\n\n\n\n\nFigure 6.2: Transfer characteristic of UWB\n\n\n\n\n\n\n\n\n\nFigure 6.3: Transfer characteristic of UWB\n\n\n\n\n\n\n\n\n\nFigure 6.4: Transfer characteristic of UWB\n\n\n\n\n\n\n\n\n\n1. 2014. A sources of error in DW1000 based two-way ranging scheme APS011. Decawave; https://www.qorvo.com/products/d/da008446.\n\n\n2. Viktor Walter, Nicolas Staub, Antonio Franchi, and Martin Saska. 2019. UVDAR system for visual relative localization with application to leader–follower formations of multirotor UAVs. IEEE Robotics and Automation Letters 4, 3: 2637–2644. https://doi.org/10.1109/LRA.2019.2901683"
  },
  {
    "objectID": "chapters/6_experiments.html#footnotes",
    "href": "chapters/6_experiments.html#footnotes",
    "title": "6  Simulations and real-world experiments",
    "section": "",
    "text": "http://mrs.felk.cvut.cz/research/micro-aerial-vehicles↩︎"
  },
  {
    "objectID": "chapters/7_conclusion.html",
    "href": "chapters/7_conclusion.html",
    "title": "7  Conclusion",
    "section": "",
    "text": "Bibliography\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nImplementation on MAV\n\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nKalman filters\n\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nSimulations and real-world experiments\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-violet Detection and Ranging\n\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-wide band\n\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2023\n\n\nVit Petrik\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "chapters/references.html",
    "href": "chapters/references.html",
    "title": "Bibliography",
    "section": "",
    "text": "1. 2011. IEEE standard for local and metropolitan\narea networks–part 15.4: Low-rate wireless personal area networks\n(LR-WPANs). IEEE Std 802.15.4-2011 (Revision of IEEE Std\n802.15.4-2006): 1–314. https://doi.org/10.1109/IEEESTD.2011.6012487\n\n\n2. 2014. A sources of error in DW1000 based\ntwo-way ranging scheme APS011. Decawave; https://www.qorvo.com/products/d/da008446.\n\n\n3. 2016. IEEE standard for low-rate wireless\nnetworks. IEEE Std 802.15.4-2015 (Revision of IEEE Std\n802.15.4-2011): 1–709. https://doi.org/10.1109/IEEESTD.2016.7460875\n\n\n4. Matej Petrlik, Pavel Petracek, Vit Kratky,\nTomas Musil, Yurii Stasinchuk, Matous Vrba, Tomas Baca, Daniel Hert,\nMartin Pecka, Tomas Svoboda, and Martin Saska. 2023. UAVs Beneath the Surface: Cooperative Autonomy for\nSubterranean Search and Rescue in DARPA SubT. Field\nRobotics 3: 1–68. https://doi.org/https://doi.org/10.55417/fr.2023001\n\n\n5. G.\nVásárhelyi, Cs. Virágh, G. Somorjai, N. Tarcai, T. Szörenyi, T. Nepusz,\nand T. Vicsek. 2014. Outdoor flocking and formation flight with\nautonomous aerial robots. In 2014 IEEE/RSJ international conference\non intelligent robots and systems, 3866–3873. https://doi.org/10.1109/IROS.2014.6943105\n\n\n6. Viktor Walter, Nicolas Staub, Antonio Franchi,\nand Martin Saska. 2019. UVDAR system for visual relative localization\nwith application to leader–follower formations of multirotor UAVs.\nIEEE Robotics and Automation Letters 4, 3: 2637–2644. https://doi.org/10.1109/LRA.2019.2901683\n\n\n7. V.\nWalter, N.Staub, M. Saska, and A. Franchi. 2018. Mutual localization of\nUAVs based on blinking ultraviolet markers and 3D time-position hough\ntransform. In 14th IEEE international conference on automation\nscience and engineering (CASE 2018).\n\n\n8. V.\nWalter, M. Saska, and A. Franchi. 2018. Fast mutual relative\nlocalization of uavs using ultraviolet led markers. In 2018\ninternational conference on unmanned aircraft system (ICUAS\n2018).\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nConclusion\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nImplementation on MAV\n\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nKalman filters\n\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nSimulations and real-world experiments\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-violet Detection and Ranging\n\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-wide band\n\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2023\n\n\nVit Petrik\n\n\n\n\n\n\nNo matching items"
  }
]