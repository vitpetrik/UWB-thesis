[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fusion of UWB-Based Distance Sensors with a Visual Relative Localization System",
    "section": "",
    "text": "1 Introduction\nIn recent years, the use of unmanned aerial vehicles (UAVs) has been rapidly growing due to their versatility and wide range of applications, from aerial photography and surveillance to delivery services 1 and search and rescue operations [1]. The problem of relative localization in UAV swarms is a critical challenge for enabling cooperative behavior and avoiding collisions.\nTo address this problem, a novel system is proposed in this thesis that combines computer vision and ultra-wideband (UWB) technology for direction and range measurements, respectively. By fusing these measurements using a Kalman filter, the relative positions and orientations of UAVs can be estimated with high accuracy, even in GNSS-denied environments such as undergrounds, buildings or caves [1]. This approach has a significant advantage over existing methods, which often rely on GNSS [2] or motion capture 2 and are therefore limited in their ability to operate in challenging environments or without additional infrastructure onsite.\nThe research question for this thesis is: How can an effective relative localization system for UAV swarms be designed and implemented using computer vision and UWB technology, and how well does it perform in real-world scenarios? Firstly, a review of the existing literature on relative localization and multi-robot systems will be conducted. Secondly, the proposed system and its key components, including the computer vision algorithms for direction estimation and the UWB hardware for range measurement, will be presented. Finally, the performance of the system will be evaluated through a series of experiments in both simulated and real-world environments and compared with existing approaches.\nBy developing and testing this system, a contribution will be made to the growing body of research on multi-robot systems and pave the way for new applications of UAV swarms in challenging environments."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Fusion of UWB-Based Distance Sensors with a Visual Relative Localization System",
    "section": "",
    "text": "Blood and packages delivery https://www.flyzipline.com↩︎\nMotion capture OptiTrack https://optitrack.com↩︎"
  },
  {
    "objectID": "chapters/2_uvdar.html",
    "href": "chapters/2_uvdar.html",
    "title": "2  Ultra-violet Detection and Ranging",
    "section": "",
    "text": "The Ultra-violet Direction and Ranging (UVDAR) is a system for relative localization based on computer vision. The system was developed by the Multi-robot system group at CTU [2]. It consists of two parts, active UV LED markers and industrial grade camera with UV bandpass filter and fisheye lens. This allows the system to exactly recognize active markers from the background and work even in a pitch-black environment. This effect can be seen in image 2.1.\n\n\n\nFigure 2.1: Image from UV camera.\n\n\n\n\n\nFigure 2.2: UVDAR processing data flow. [1]\n\n\n\n\n\n\n\n1. V. Walter, N.Staub, M. Saska, and A. Franchi. 2018. Mutual localization of UAVs based on blinking ultraviolet markers and 3D time-position hough transform. In 14th IEEE international conference on automation science and engineering (CASE 2018).\n\n\n2. V. Walter, M. Saska, and A. Franchi. 2018. Fast mutual relative localization of uavs using ultraviolet led markers. In 2018 international conference on unmanned aircraft system (ICUAS 2018).\n\n\n\n\n\n\n\n  \n\n\n\n\nBibliography\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nConclusion\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nImplementation on MAV\n\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nKalman filters\n\n\n\n\n\n\n\n\n\n\n\n\nMay 21, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nSimulations and real-world experiments\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-wide band\n\n\n\n\n\n\n\n\n\n\n\n\nMay 15, 2023\n\n\nVit Petrik\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "chapters/3_uwb.html#mac-layer",
    "href": "chapters/3_uwb.html#mac-layer",
    "title": "3  Ultra-wide band",
    "section": "3.1 MAC layer",
    "text": "3.1 MAC layer\nIEEE 802.15.4 describes the MAC layer for low-rate wireless personal networks, including UWB. The MAC layer is responsible for coordinating access to the shared wireless channel, managing network associations and disassociations, and providing security and reliability features. The MAC layer inserts a MAC header and a MAC footer before and after a network-layer frame, respectively. The MAC header contains information such as frame type, source and destination addresses, sequence number, and security parameters. The MAC footer contains a CRC check. The IEEE 802.15.4 MAC layer supports two modes of operation: beacon-enabled and non-beacon-enabled. In beacon-enabled mode, a coordinator device periodically broadcasts beacons to synchronize the devices in its network and allocate contention-free periods for data transmission. In non-beacon-enabled mode, devices use a slotted or unslotted carrier sense multiple access with collision avoidance (CSMA-CA) mechanism to access the channel. The exact layout of MAC frame format is described in Table [tbl-mac-frame].\n‘\n\nwidth=\n\n|ccccccc|c|c| & & & & & & 0/5/6/10/14 & variable & 2\n& & & & & & & &\n& & & & &\n&\n\n\n\n\n(a) MAC frame format.\n\n\nMAC\n\n\nPayload\n\n\n\n\n\n\nTable 3.1: ?(caption)\n\n\n& MFR"
  },
  {
    "objectID": "chapters/3_uwb.html#physical-layer",
    "href": "chapters/3_uwb.html#physical-layer",
    "title": "3  Ultra-wide band",
    "section": "3.2 Physical Layer",
    "text": "3.2 Physical Layer\nThe physical (PHY) layer of UWB was described in IEEE 802.15.4-2011 [1] as UWB PHY. Later in IEEE 802.15.4-2015 [3] the PHY was named as High repetition pulse (HRP) UWB PHY. This decision was made due to the introduction of Low repetition pulse (LRP) UWB PHY. Only the HRP UWB PHY will be discussed. The standard defines three operation bands:\n\nsub-gigahertz band consisting of single a channel spectrum from 249.6 MHz to 749.6 MHz.\nLow band with spectrum from 3.1 GHz to 4.8 GHz.\nHigh band with spectrum from 6 GHz to 10.6 GHz.\n\n\n\n\nFigure 3.2: Data flow according to [1].\n\n\nIt uses an impulse radio signaling scheme with band-limited pulses and supports high data rates and precision ranging applications. It also uses a combination of burst position modulation (BPM) and binary phase-shift keying (BPSK) to modulate symbols. The overview of the physical layer is expressed in figure 3.2.\n\nPPDU format\nEach physical layer protocol data unit (PPDU) consists of a preamble, PHY header, and the data itself. The process of encoding the whole PPDU can be seen in figure 3.3.\nReed-Solomon encoding is used to encode the physical service data unit (PSDU) of the HRP UWB PHY. It adds redundant symbols to the original message symbols to form a codeword that can be decoded using polynomial interpolation or factorization techniques. Reed-Solomon encoding improves the error-correction performance of the HRP UWB PHY and enables it to handle burst errors or random errors that may occur in the wireless channel 4.\nConvolutional encoding is used to encode the PSDU of the HRP UWB PHY after Reed-Solomon encoding. It uses a finite state machine with memory cells to generate output bits based on the current and previous input bits. It adds parity bits to the original information bits to form a codeword that can be decoded using Viterbi algorithm or other sequential decoding techniques. Convolutional encoding improves the error-correction performance of the HRP UWB PHY and enables it to handle noisy or fading channels.\n\n\n\nFigure 3.3: PPDU encoding process [1].\n\n\nA preamble in HRP UWB PHY is a sequence of known bits sent at the beginning of each frame. It is used for frame synchronization, channel estimation, and ranging measurements. It consists of two parts: a synchronization header (SHR) 3.4 and a physical layer header (PHR) 3.5.\nThe SHR contains a preamble symbol (SYNC) and a start-of-frame delimiter (SFD). The SFD is a fixed sequence of pulses that indicates the start of a frame. The PS is a burst of UWB pulses that can be modulated by burst position modulation (BPM) or binary phase-shift keying (BPSK). The preamble symbol repetitions (PSR) define the number of repeated sequences, ranging from 16 to 4,096 repetitions.\n\n\n\nFigure 3.4: SHR field structure. [3]\n\n\nThe PHR contains information about the data to be received, including the length of the data and the data rate used to transmit the data. It also contains additional information elements to facilitate ranging information exchange\n\n\n\nFigure 3.5: PHR field structure. [3]\n\n\n\n\n3.2.1 Symbol structure\nA symbol 3.7 is the basic unit of information in HWP UWB PHY. It consists of a short burst of UWB pulses that lasts for 2 ns and occupies a bandwidth of 0.5-1.3 GHz. The burst can be placed in one of the two possible burst intervals, and its phase can be inverted or not. These two choices allow each symbol to carry two bits of information using burst position modulation (BPM) and binary phase-shift keying (BPSK), a example of the modulation can be found in figure 3.6.\n\n\n\n\n\nFigure 3.6: Example of BPM-BPSK modulation,\n\n\n\n\nBurst hopping position is a parameter that determines the time position of the UWB pulses within a burst interval. Scrambling code is a pseudo-random sequence that is applied to the data bits before modulation. It is used to randomize the data bits and reduce the peak-to-average power ratio (PAPR) of the UWB pulses.\n\n\n\nFigure 3.7: Symbol stucture. [3]\n\n\nIEEE defines the reference pulse as a root-raised cosine pulse with roll-off factor \\(\\beta = 0.5\\) 3.3.\n\\[         \nr(t) = \\frac{4 \\beta}{\\pi \\sqrt{T_p}} \\frac{\\cos{[(1+ \\beta) \\pi t / T_p]} + \\frac{\\sin{[(1 - \\beta) \\pi t / T_p}]}{4 \\beta(t / T_p)}}{1-(4 \\beta t /  T_p)^2}\n\\tag{3.3}\\]\nParameter \\(T_p\\) stands for duration of the pulse. The duration is defined for each channel by table 3.2.\n\n\nTable 3.2: Reference pulse duration for each channel. [1]\n\n\n\n\n\n\n\nChannel number\nPulse duration \\(T_p\\) (ns)\nMain lobe width \\(T_w\\) (ns)\n\n\n\n\n{0:3, 5:6, 8:10, 12:14}\n2.00\n0.5\n\n\n7\n0.92\n0.2\n\n\n{4, 11}\n0.75\n0.2\n\n\n15\n0.74\n0.2\n\n\n\n\nFigure 3.8 further illustrates a waveform of the pulse. However an actual hardware system cannot fully realize the shape of the reference pulse. Therefore IEEE 802.15.4 constrains transmitted pulse \\(p(t)\\) by a cross-correlation function 3.4.\n\\[\n    \\mathrm{\\phi}(\\tau) = \\frac{1}{\\sqrt{E_r E_p}} Re \\int^{\\infty}_{-\\infty} \\mathrm{r}(t) \\mathrm{p}(t - \\tau) \\mathrm{dt}\n\\tag{3.4}\\] Where:\n\\[\\begin{aligned}\n    E_r &= \\text{energy of r(t)} \\\\\n    E_p &= \\text{energy of p(t)} \\\\\n\\end{aligned}\\]\nFor PHY to be IEEE compliant the main lobe of the transmitted pulse must have a magnitude of cross correlation \\(|\\phi(\\tau)|\\) at least 0.8, and the magnitude of sidelobes must not be greater than 0.3.\n\n\n\n\n\nFigure 3.8: Reference pulse of UWB radio."
  },
  {
    "objectID": "chapters/3_uwb.html#ranging-techniques",
    "href": "chapters/3_uwb.html#ranging-techniques",
    "title": "3  Ultra-wide band",
    "section": "3.3 Ranging techniques",
    "text": "3.3 Ranging techniques\n\nTime Difference of Arrival\nTime difference of arrival (TDOA) position estimation is a technique that uses the difference in the arrival times of UWB signals at multiple receivers to estimate the position of a transmitter.\nTDOA position estimation requires at least four receivers for 3D localization and one transmitter. The receivers measure the time of arrival (TOA) of the UWB signals. The TOA measurements are then used to calculate the TDOA values between different pairs of receivers [6].\nTo estimate the position of the transmitter system of equations 3.5 is solved [4]. For\n\\[\n    \\sqrt{\\mathbf{x_r}^T \\mathbf{\\hat{x}}} - \\sqrt{\\mathbf{x_i}^T \\mathbf{\\hat{x}}} = c(t_r - t_i)\n\\tag{3.5}\\] Where:\n\\[\\begin{aligned}\n    \\mathbf{\\hat{x}} &= \\text{estimated position of the transmitter.} \\\\\n    \\mathbf{x_r} &= \\text{Position of the reference receiver.} \\\\\n    \\mathbf{x_i} &= \\text{Position of receiver \\textit{i}.} \\\\\n    t_r &= \\text{Time of arrival for the reference receiver.} \\\\\n    t_r &= \\text{Time of arrival for the receiver \\textit{i}.} \\\\\n    c &= \\text{Speed of light.} \\\\\n\\end{aligned}\\]\nThe main challenge for implementing TDoA is synchronizing the clock across all receivers [5].\nThe TDoA system can be used in a variety of applications, such as indoor positioning, tracking of vehicles or people, and asset tracking. The accuracy of the TDoA system depends on the number and placement of the UWB sensors and the timing resolution of the system.\n\n\nTwo way ranging\nTwo-way ranging (TWR) is a technique used by UWB systems to estimate the distance between two devices. TWR requires two-way communication between two devices, where one device sends a signal to another device and waits for a response, as shown in figure 3.9. The time difference between the transmission and reception of the signal is used to calculate the distance between the two devices.\n\n\n\nFigure 3.9: Two way ranging with two round trips.\n\n\nSingle-sided two-way ranging (SS-TWR) is a technique where only one device sends a signal and waits for a response from another device. The time difference between the transmission and reception of the signal is used to calculate the distance between the two devices. \\[\n    \\mathrm{TOF} = \\frac{R_a - D_b}{2}\n\\] Where:\n\\[\\begin{aligned}\n    \\mathrm{TOF} &= \\text{Time of flight.} \\\\\n    R_a &= \\text{Time of round trip} \\\\\n    D_b &= \\text{Response delay.} \\\\\n\\end{aligned}\\]\nDouble-sided two-way ranging (DS-TWR) is a technique where both devices send signals and wait for responses from each other. The time difference between the transmission and reception of signals from both devices is used to calculate the distance between them.\n\\[\n    \\mathrm{TOF} = \\frac{R_a R_b - D_a D_b}{R_a + D_a + R_b + D_b}\n\\]\nDS-TWR’s main advantage is its ability to compensate for the effect of clock drift [2]. Clock drift refers to several related phenomena where a clock does not run at exactly the same rate as a reference clock. That is, after some time the clock “drifts apart” or gradually desynchronizes from the other clock. All clocks are subject to drift, causing eventual divergence unless resynchronized. Clock drift can be caused by many factors, such as temperature changes, aging of components, and power supply voltage changes [2].\n\n\n\n\n\n1. 2011. IEEE standard for local and metropolitan area networks–part 15.4: Low-rate wireless personal area networks (LR-WPANs). IEEE Std 802.15.4-2011 (Revision of IEEE Std 802.15.4-2006): 1–314. https://doi.org/10.1109/IEEESTD.2011.6012487\n\n\n2. 2014. A sources of error in DW1000 based two-way ranging scheme APS011. Decawave; https://www.qorvo.com/products/d/da008446.\n\n\n3. 2016. IEEE standard for low-rate wireless networks. IEEE Std 802.15.4-2015 (Revision of IEEE Std 802.15.4-2011): 1–709. https://doi.org/10.1109/IEEESTD.2016.7460875\n\n\n4. MathWorks. 2021. Object tracking using time difference of arrival. \n\n\n5. Yan Xie, Gerard J. M. Janssen, and Alle-Jan van der Veen. 2016. A practical clock synchronization algorithm for UWB positioning systems. In 2016 IEEE international conference on acoustics, speech and signal processing (ICASSP), 3891–3895. https://doi.org/10.1109/ICASSP.2016.7472406\n\n\n6. Wenda Zhao, Abhishek Goudar, and Angela P. Schoellig. 2022. Finding the right place: Sensor placement for UWB time difference of arrival localization in cluttered indoor environments. IEEE Robotics and Automation Letters 7, 3: 6075–6082. https://doi.org/10.1109/LRA.2022.3165181"
  },
  {
    "objectID": "chapters/3_uwb.html#footnotes",
    "href": "chapters/3_uwb.html#footnotes",
    "title": "3  Ultra-wide band",
    "section": "",
    "text": "Apple AirTag https://www.apple.com/airtag/↩︎\nSiemens RTLS https://www.siemens.com/global/en/products/automation/industrial-identification/simatic-rtls.html/↩︎\nSewio real-time location system https://www.sewio.net/↩︎\nMathworks HRP UWB IEEE 802.15.4a/z Waveform Generation https://www.mathworks.com/help/comm/ug/hrp-uwb-ieee-802.15.4az-waveform-generation.html↩︎"
  },
  {
    "objectID": "chapters/4_kalman.html#linear-kalman-filter",
    "href": "chapters/4_kalman.html#linear-kalman-filter",
    "title": "4  Kalman filters",
    "section": "4.1 Linear Kalman filter",
    "text": "4.1 Linear Kalman filter\nA linear Kalman filter is a recursive algorithm that uses the Bode-Shannon representation of random processes and the state-transition method of analysis of dynamic systems to estimate the state of a system from noisy measurements. It assumes that the system and the measurements are linear and Gaussian, meaning that they can be expressed as matrix operations with additive noise. The algorithm consists of two steps: prediction and correction. In the prediction step 4.1, the algorithm uses a state transition matrix to project the current state and its covariance matrix to the next time step.\n\\[\n\\begin{aligned}\n    \\mathbf{\\hat{x}} &= \\mathbf{F x + Bu} \\\\\n    \\mathbf{\\hat{P}} &= \\mathbf{F P F^{T} + Q}\n\\end{aligned}\n\\tag{4.1}\\] Where:\n\\[\\begin{aligned}\n    \\mathbf{\\hat{x}}, \\mathbf{\\hat{P}} &= \\text{State mean and covariance} \\\\\n    \\mathbf{F} &= \\text{Transition matrix} \\\\\n    \\mathbf{Q} &= \\text{Process matrix} \\\\\n    \\mathbf{B, u} &= \\text{Input to the system} \\\\\n\\end{aligned}\\]\nIn the correction step 4.2, the algorithm uses a measurement matrix to update the predicted state and its covariance matrix with the new measurement. The algorithm optimizes the estimation by minimizing the mean squared error between the true state and the estimated state [1].\n\\[\n\\begin{aligned}\n    \\mathbf{y} &= \\mathbf{z - H x} \\\\\n    \\mathbf{K} &= \\mathbf{P H^T (H P H^T + R)^{-1}} \\\\\n    \\mathbf{\\hat{x}} &= \\mathbf{x + K y} \\\\\n    \\mathbf{\\hat{P}} &= \\mathbf{(I - K H)P} \\\\\n\\end{aligned}\n\\tag{4.2}\\] Where:\n\\[\\begin{aligned}\n    \\mathbf{z}, \\mathbf{R} &= \\text{Measurement and convariance} \\\\\n    \\mathbf{H} &= \\text{Measurement function} \\\\\n\\end{aligned}\\]"
  },
  {
    "objectID": "chapters/4_kalman.html#unscented-kalman-filter",
    "href": "chapters/4_kalman.html#unscented-kalman-filter",
    "title": "4  Kalman filters",
    "section": "4.2 Unscented Kalman filter",
    "text": "4.2 Unscented Kalman filter\nThe unscented Kalman filter (UKF) is a technique for nonlinear estimation that uses a deterministic sampling approach to propagate a Gaussian random variable through the system dynamics [5]. The UKF employs the unscented transformation (UT), which generates a set of sample points that capture the mean and covariance of the original distribution.\nThe unscented transform is a technique for approximating the outcome of applying a nonlinear function to a probability distribution that is described by a mean and a covariance matrix. It does this by choosing a set of points, known as sigma points Figure 4.1.\n\n\n\nFigure 4.1: Comparsion between sampling, EKF and sigma points. [3]\n\n\nMerwe describes generating the sigma points in his dissertation thesis [3]. These sigma points are chosen to capture the mean and covariance of the current estimated state, and they are transformed through the nonlinear model to predict the state at the next time step. The sigma points \\(\\mathbfcal{X}_i\\) as well as weights \\(\\omega_i\\) for each point are calculated using equation 4.3. The weights \\(\\omega_i\\) must follow equation \\(\\sum_{i=0}^{2L} \\omega_i = 1\\).\n\\[\\begin{gathered}\n\\lambda = \\alpha^2 (L + \\kappa) - L\n\\end{gathered}\\] \\[\n\\begin{aligned}\n    \\mathbfcal{X_0} &= \\bar{x}   &  \\omega^{m}_0 &= \\frac{\\lambda}{L + \\lambda} & i &= 0  \\\\\n    \\mathbfcal{X_i} &= \\bar{x} + \\left( \\sqrt{(L+\\lambda) \\mathbf{P_x}} \\right)_i   &  \\omega^{c}_i &= \\frac{1}{2(L + \\lambda)} + (1 − \\alpha^2 + \\beta) & i &= 1,..., L \\\\\n    \\mathbfcal{X_i} &= \\bar{x} - \\left( \\sqrt{(L+\\lambda) \\mathbf{P_x}} \\right)_i & \\omega^{m}_i &= \\omega^{c}_i = \\frac{1}{2(L +\\lambda)} & i &= L+1,...,2L\n\\end{aligned}\n\\tag{4.3}\\] Where:\n\\[\\begin{gathered}\n\\begin{align*}\n    \\mathbf{\\hat{x}}, \\mathbf{P_x} &= \\text{State vector and covariance} \\\\\n    L &= \\text{Dimension of state vector}\n\\end{align*}\n\\\\\n0 \\leq \\alpha \\leq 1 \\\\\n0 \\leq \\kappa \\\\\n0 \\leq \\beta\n\\end{gathered}\\]\nThe sigma points are used both in predict step 4.4 and update step 4.5 and need to be regenerated for each new measurement. Instead of matrix \\(\\mathbf{F}\\) 4.1 and \\(\\mathbf{H}\\) 4.2 known from LKF, the UKF is provided with nonlinear functions \\(\\mathbf{f(} \\mathbfcal{X} \\mathbf{)}\\) and \\(\\mathbf{h(} \\mathbfcal{X} \\mathbf{)}\\).\n\\[\n\\begin{gathered}\n    \\textit{Predict step} \\\\\n    \\hline\n    \\mathbfcal{Y} = \\mathbf{f(} \\mathbfcal{X} \\mathbf{)} \\\\\n    \\mathbf{\\hat{x}} = \\sum_{i=0}^{2L} \\omega^m_i \\mathbfcal{Y}_i \\quad\\quad\n    \\mathbf{\\hat{P}} = \\sum_{i=0}^{2L} \\omega^c_i (\\mathbfcal{Y}_i - \\mathbf{x})(\\mathbfcal{Y}_i - \\mathbf{x})^T + \\mathbf{Q}\n\\end{gathered}\n\\tag{4.4}\\]\nBy comparing the predicted measurements with the actual measurements, the UKF computes the Kalman gain, which determines the optimal blend between the predicted state and the measurement updates. Finally, the updated state estimate is obtained by incorporating the measurement information into the predicted state estimate using the Kalman gain. The update step of the UKF enables the filter to adaptively adjust the state estimate based on the measurements, providing a more accurate estimation of the system’s true state.\n\\[\n\\begin{gathered}\n    \\textit{Update step} \\\\\n    \\hline\n    \\mathbfcal{Z} = \\mathbf{h(} \\mathbfcal{X} \\mathbf{)} \\\\\n    \\mathbf{\\mu}_z = \\sum_{i=0}^{2L} \\omega^m_i \\mathbfcal{Z}_i \\quad\\quad\n    \\mathbf{P}_z = \\sum_{i=0}^{2L} \\omega^c_i (\\mathbfcal{Z}_i - \\mathbf{\\mu}_z)(\\mathbfcal{Z}_i - \\mathbf{\\mu}_z)^T + \\mathbf{R} \\\\\n    \\mathbf{y} = \\mathbf{z} - \\mathbf{\\mu}_z \\qquad \\mathbf{P}_{xz} = \\sum_{i=0}^{2L} \\omega_i^c (\\mathbfcal{X}_i - \\mathbf{x}) (\\mathbfcal{Z}_i - \\mathbf{\\mu}_z)^T \\\\\n    \\mathbf{K} = \\mathbf{P}_{xz} \\mathbf{P}_z^{-1} \\\\\n    \\mathbf{\\hat{x}} = \\mathbf{x} + \\mathbf{K} \\mathbf{y} \\qquad \\mathbf{\\hat{P}} = \\mathbf{P} - \\mathbf{K} \\mathbf{P}_z \\mathbf{K}^T\n\\end{gathered}\n\\tag{4.5}\\]\nThe UKF has been shown to achieve higher accuracy and robustness than the extended Kalman filter (EKF) for various nonlinear estimation problems, such as state estimation, parameter estimation, and dual estimation [5].\n\n\n\n\n\n1. R. E. Kalman. 1960. A New Approach to Linear Filtering and Prediction Problems. Journal of Basic Engineering 82, 1: 35–45. https://doi.org/10.1115/1.3662552\n\n\n2. Priya Shree Madhukar and L. B. Prasad. 2020. State estimation using extended kalman filter and unscented kalman filter. In 2020 international conference on emerging trends in communication, control and computing (ICONC3), 1–4. https://doi.org/10.1109/ICONC345789.2020.9117536\n\n\n3. Rudolph Merwe and Eric Wan. 2003. Sigma-point kalman filters for probabilistic inference in dynamic state-space models. Proceedings of the Workshop on Advances in Machine Learning.\n\n\n4. M. St-Pierre and D. Gingras. 2004. Comparison between the unscented kalman filter and the extended kalman filter for the position estimation module of an integrated navigation information system. In IEEE intelligent vehicles symposium, 2004, 831–835. https://doi.org/10.1109/IVS.2004.1336492\n\n\n5. E. A. Wan and R. Van Der Merwe. 2000. The unscented kalman filter for nonlinear estimation. In Proceedings of the IEEE 2000 adaptive systems for signal processing, communications, and control symposium (cat. no.00EX373), 153–158. https://doi.org/10.1109/ASSPCC.2000.882463"
  },
  {
    "objectID": "chapters/5_implementation.html",
    "href": "chapters/5_implementation.html",
    "title": "5  Implementation on MAV",
    "section": "",
    "text": "Bibliography\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nConclusion\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nKalman filters\n\n\n\n\n\n\n\n\n\n\n\n\nMay 21, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nSimulations and real-world experiments\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-violet Detection and Ranging\n\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-wide band\n\n\n\n\n\n\n\n\n\n\n\n\nMay 15, 2023\n\n\nVit Petrik\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "chapters/6_experiments.html#results",
    "href": "chapters/6_experiments.html#results",
    "title": "6  Simulations and real-world experiments",
    "section": "6.1 Results",
    "text": "6.1 Results\nAll proposed experiments were successfully conducted. The first experiment [Figure 6.2] showed that the UWB measurements are indeed precise and do not express any signs of nonlinearity. The maximum range of 120 m was reached by UWB, however, the measurements at the far end are not reliable and often drops out. This can be seen as straight lines in Figure 6.2. Somehow cite this [1]\n\n\n\n\n\nFigure 6.2: Transfer characteristic of UWB\n\n\n\n\n\n\n\n\n\nFigure 6.3: Transfer characteristic of UWB\n\n\n\n\n\n\n\n\n\nFigure 6.4: Transfer characteristic of UWB\n\n\n\n\n\n\n\n\n\n1. 2014. A sources of error in DW1000 based two-way ranging scheme APS011. Decawave; https://www.qorvo.com/products/d/da008446.\n\n\n2. Viktor Walter, Nicolas Staub, Antonio Franchi, and Martin Saska. 2019. UVDAR system for visual relative localization with application to leader–follower formations of multirotor UAVs. IEEE Robotics and Automation Letters 4, 3: 2637–2644. https://doi.org/10.1109/LRA.2019.2901683"
  },
  {
    "objectID": "chapters/6_experiments.html#footnotes",
    "href": "chapters/6_experiments.html#footnotes",
    "title": "6  Simulations and real-world experiments",
    "section": "",
    "text": "http://mrs.felk.cvut.cz/research/micro-aerial-vehicles↩︎"
  },
  {
    "objectID": "chapters/7_conclusion.html",
    "href": "chapters/7_conclusion.html",
    "title": "7  Conclusion",
    "section": "",
    "text": "Bibliography\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nImplementation on MAV\n\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nKalman filters\n\n\n\n\n\n\n\n\n\n\n\n\nMay 21, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nSimulations and real-world experiments\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-violet Detection and Ranging\n\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-wide band\n\n\n\n\n\n\n\n\n\n\n\n\nMay 15, 2023\n\n\nVit Petrik\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "chapters/references.html",
    "href": "chapters/references.html",
    "title": "Bibliography",
    "section": "",
    "text": "1. 2011. IEEE standard for local and metropolitan\narea networks–part 15.4: Low-rate wireless personal area networks\n(LR-WPANs). IEEE Std 802.15.4-2011 (Revision of IEEE Std\n802.15.4-2006): 1–314. https://doi.org/10.1109/IEEESTD.2011.6012487\n\n\n2. 2014. A sources of error in DW1000 based\ntwo-way ranging scheme APS011. Decawave; https://www.qorvo.com/products/d/da008446.\n\n\n3. 2016. IEEE standard for low-rate wireless\nnetworks. IEEE Std 802.15.4-2015 (Revision of IEEE Std\n802.15.4-2011): 1–709. https://doi.org/10.1109/IEEESTD.2016.7460875\n\n\n4. R.\nE. Kalman. 1960. A New Approach to Linear Filtering\nand Prediction Problems. Journal of Basic Engineering\n82, 1: 35–45. https://doi.org/10.1115/1.3662552\n\n\n5. Priya Shree Madhukar and L. B. Prasad. 2020.\nState estimation using extended kalman filter and unscented kalman\nfilter. In 2020 international conference on emerging trends in\ncommunication, control and computing (ICONC3), 1–4. https://doi.org/10.1109/ICONC345789.2020.9117536\n\n\n6. MathWorks. 2021. Object tracking using time\ndifference of arrival. \n\n\n7. Rudolph Merwe and Eric Wan. 2003. Sigma-point\nkalman filters for probabilistic inference in dynamic state-space\nmodels. Proceedings of the Workshop on Advances in Machine\nLearning.\n\n\n8. Matej Petrlik, Pavel Petracek, Vit Kratky,\nTomas Musil, Yurii Stasinchuk, Matous Vrba, Tomas Baca, Daniel Hert,\nMartin Pecka, Tomas Svoboda, and Martin Saska. 2023. UAVs Beneath the Surface: Cooperative Autonomy for\nSubterranean Search and Rescue in DARPA SubT. Field\nRobotics 3: 1–68. https://doi.org/https://doi.org/10.55417/fr.2023001\n\n\n9. M.\nSt-Pierre and D. Gingras. 2004. Comparison between the unscented kalman\nfilter and the extended kalman filter for the position estimation module\nof an integrated navigation information system. In IEEE intelligent\nvehicles symposium, 2004, 831–835. https://doi.org/10.1109/IVS.2004.1336492\n\n\n10. G.\nVásárhelyi, Cs. Virágh, G. Somorjai, N. Tarcai, T. Szörenyi, T. Nepusz,\nand T. Vicsek. 2014. Outdoor flocking and formation flight with\nautonomous aerial robots. In 2014 IEEE/RSJ international conference\non intelligent robots and systems, 3866–3873. https://doi.org/10.1109/IROS.2014.6943105\n\n\n11. Viktor Walter, Nicolas Staub, Antonio Franchi,\nand Martin Saska. 2019. UVDAR system for visual relative localization\nwith application to leader–follower formations of multirotor UAVs.\nIEEE Robotics and Automation Letters 4, 3: 2637–2644. https://doi.org/10.1109/LRA.2019.2901683\n\n\n12. V.\nWalter, N.Staub, M. Saska, and A. Franchi. 2018. Mutual localization of\nUAVs based on blinking ultraviolet markers and 3D time-position hough\ntransform. In 14th IEEE international conference on automation\nscience and engineering (CASE 2018).\n\n\n13. V.\nWalter, M. Saska, and A. Franchi. 2018. Fast mutual relative\nlocalization of uavs using ultraviolet led markers. In 2018\ninternational conference on unmanned aircraft system (ICUAS\n2018).\n\n\n14. E.\nA. Wan and R. Van Der Merwe. 2000. The unscented kalman filter for\nnonlinear estimation. In Proceedings of the IEEE 2000 adaptive\nsystems for signal processing, communications, and control symposium\n(cat. no.00EX373), 153–158. https://doi.org/10.1109/ASSPCC.2000.882463\n\n\n15. Yan\nXie, Gerard J. M. Janssen, and Alle-Jan van der Veen. 2016. A practical\nclock synchronization algorithm for UWB positioning systems. In 2016\nIEEE international conference on acoustics, speech and signal processing\n(ICASSP), 3891–3895. https://doi.org/10.1109/ICASSP.2016.7472406\n\n\n16. Wenda Zhao, Abhishek Goudar, and Angela P.\nSchoellig. 2022. Finding the right place: Sensor placement for UWB time\ndifference of arrival localization in cluttered indoor environments.\nIEEE Robotics and Automation Letters 7, 3: 6075–6082. https://doi.org/10.1109/LRA.2022.3165181\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nConclusion\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nImplementation on MAV\n\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nKalman filters\n\n\n\n\n\n\n\n\n\n\n\n\nMay 21, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nSimulations and real-world experiments\n\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-violet Detection and Ranging\n\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-wide band\n\n\n\n\n\n\n\n\n\n\n\n\nMay 15, 2023\n\n\nVit Petrik\n\n\n\n\n\n\nNo matching items"
  }
]