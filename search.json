[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fusion of UWB-Based Distance Sensors with a Visual Relative Localization System",
    "section": "",
    "text": "1 Introduction\nIn recent years, the use of unmanned aerial vehicles (UAVs) has been rapidly growing due to their versatility and wide range of applications, from aerial photography and surveillance to delivery services 1 and search and rescue operations [1]. The problem of relative localization in UAV swarms is a critical challenge in enabling cooperative behavior and avoiding collisions.\nTo address this problem, a novel system is proposed in this thesis that combines computer vision and ultra-wideband (UWB) technology for direction and range measurements, respectively. By combining these measurements with a Kalman filter, the relative positions and orientations of UAVs can be estimated with high accuracy, even in GNSS-denied environments such as buildings or underground areas [1]. This approach has a significant advantage over existing methods, which often rely on GNSS [2] or motion capture 2 and are therefore limited in their ability to operate in challenging environments or without additional infrastructure onsite.\nThis thesis addresses designing and implementing an effective relative localization system for UAV swarms using computer vision and UWB technology and evaluates how well it performs in real-world scenarios. First, a review of the proposed system and its key components, including the computer vision algorithms for direction estimation and the UWB hardware for range measurement, will be presented. Finally, the performance of the system will be evaluated through a series of experiments in both simulated and real-world environments.\nBy developing and testing this system, a contribution will be made to the growing body of research on multi-robot systems and pave the way for new applications of UAV swarms in challenging environments."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Fusion of UWB-Based Distance Sensors with a Visual Relative Localization System",
    "section": "",
    "text": "Blood and packages delivery https://www.flyzipline.com↩︎\nMotion capture OptiTrack https://optitrack.com↩︎"
  },
  {
    "objectID": "chapters/2_uvdar.html",
    "href": "chapters/2_uvdar.html",
    "title": "2  Ultra-violet Direction and Ranging",
    "section": "",
    "text": "The Ultra-violet Direction and Ranging (UVDAR) system, developed by the esteemed Multi-robot system group at CTU [3], revolutionizes relative localization through the implementation of computer vision techniques. Comprised of active UV LED markers (395nm) and an industrial-grade camera (mvBlueFOX MLC200wG) equipped with a UV bandpass filter and fisheye lens, UVDAR excels at accurately distinguishing active markers from the background. This exceptional capability enables the system to operate effectively under diverse lighting conditions, ensuring reliable performance. For a visual representation of the UVDAR system, refer to Figure 2.1, which provides an example view captured by the camera with extracted bright spots.\n\n\n\nFigure 2.1: Image from UV camera with extracted bright spots.\n\n\nFigure 2.2 presents a comprehensive overview of the UVDAR system, showcasing its data flow and functionality.\n\n\n\nFigure 2.2: UVDAR processing data flow.\n\n\nThe bright points detector step uses Features from accelerated segment test (FAST) algorithm to extract the UV markers. The FAST algorithm is a method for detecting corners in images, which are useful for tracking and mapping objects in 3D model-based tracking systems. It was introduced by Edward Rosten and Tom Drummond in 2005 [1]. It uses a 16-pixel circle around a candidate point and compares the intensity of the pixels with a threshold to determine if the point is a corner. It also uses a high-speed test and machine learning techniques to improve the performance and accuracy of the corner detection [1]. The FAST algorithm can perform full-frame real-time feature detection and can handle large prediction errors and rapid movements [1]. The implementation of the FAST algorithm can distinguish sun and UV markers, as the sun is a major UV light source. Recently great effort was made by MRS group to implement FAST using GPU resources to offload CPU.\nThe extract blinking signals step uses 4D hough tranformation to evaluate the blinking frequency of the UV LED marker. The step involves buffering the extracted bright points as t-points \\(\\begin{bmatrix} x & y & t \\end{bmatrix}\\) from multiple frames and processing them by the Hough transformation [2]. The Hough transformation is used to approximate the motion of t-points with t-lines. The presence of t-points within t-lines is used to match a blinking signal with a predefined sequence ID.\nThe pose calculator will perform the final result, as it can assign the retrieved markers to a physical UAV model, estimate its position, orientation and covariance matrix. Figure 2.3 provides a visual representation of the geometric interpretation involved in the pose calculation process.\n\n\n\nFigure 2.3: Geometry of UAV position calculation with 3 visible markers. [3]\n\n\n\n\n\n\n\n1. E. Rosten and T. Drummond. 2005. Fusing points and lines for high performance tracking. In Tenth IEEE international conference on computer vision (ICCV’05) volume 1, 1508–1515 Vol. 2. https://doi.org/10.1109/ICCV.2005.104\n\n\n2. V. Walter, N.Staub, M. Saska, and A. Franchi. 2018. Mutual localization of UAVs based on blinking ultraviolet markers and 3D time-position hough transform. In 14th IEEE international conference on automation science and engineering (CASE 2018).\n\n\n3. V. Walter, M. Saska, and A. Franchi. 2018. Fast mutual relative localization of uavs using ultraviolet led markers. In 2018 international conference on unmanned aircraft system (ICUAS 2018).\n\n\n\n\n\n\n\n  \n\n\n\n\nConclusion\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nKalman filters\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nReferences\n\n\n\n\n\n\n\n\n\n\n\n\nMay 22, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nSimulations and real-world experiments\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nSource code\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUAV implementation\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-wide band\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "chapters/3_uwb.html#mac-layer",
    "href": "chapters/3_uwb.html#mac-layer",
    "title": "3  Ultra-wide band",
    "section": "3.1 MAC layer",
    "text": "3.1 MAC layer\nIEEE 802.15.4 describes the MAC layer for low-rate wireless personal networks, including UWB. The MAC layer is responsible for coordinating access to the shared wireless channel, managing network associations and disassociations, and providing security and reliability features. The MAC layer inserts an MAC header and an MAC footer before and after a network-layer frame, respectively. The MAC header contains information such as frame type, source and destination addresses, sequence number, and security parameters. The MAC footer contains a CRC check. The IEEE 802.15.4 MAC layer supports two modes of operation: beacon-enabled and non-beacon-enabled. In beacon-enabled mode, a coordinator device periodically broadcasts beacons to synchronize devices on its network and allocate contention-free periods for data transmission. In non-beacon-enabled mode, devices use a slotted or unslotted carrier sense multiple access with collision avoidance (CSMA-CA) mechanism to access the channel. The exact layout of the MAC frame format is described in Table [tbl-mac-frame].\n‘\n\nwidth=\n\n|ccccccc|c|c| & & & & & & 0/5/6/10/14 & variable & 2\n& & & & & & & &\n& & & & &\n&\n\n\n\n\n(a) MAC frame format. [3]\n\n\nMAC\n\n\nPayload\n\n\n\n\n\n\nTable 3.1: ?(caption)\n\n\n& MFR"
  },
  {
    "objectID": "chapters/3_uwb.html#physical-layer",
    "href": "chapters/3_uwb.html#physical-layer",
    "title": "3  Ultra-wide band",
    "section": "3.2 Physical Layer",
    "text": "3.2 Physical Layer\nThe physical layer (PHY) of the UWB was described in IEEE 802.15.4-2011 [1] as the UWB PHY. Later in IEEE 802.15.4-2015 [3] the PHY was named High repetition pulse (HRP) UWB PHY. This decision was made due to the introduction of Low repetition pulse (LRP) UWB PHY. Only the HRP UWB PHY will be discussed. The standard defines three operation bands:\n\nsub-gigahertz band consisting of a single channel spectrum from 249.6 MHz to 749.6 MHz.\nLow band with spectrum from 3.1 GHz to 4.8 GHz.\nHigh band with spectrum from 6 GHz to 10.6 GHz.\n\n\n\n\nFigure 3.1: Data flow according to. [1]\n\n\nThe PHY uses an impulse radio signaling scheme with band-limited pulses and supports high data rates and precise ranging applications. It also uses a combination of burst position modulation (BPM) and binary phase-shift keying (BPSK) to modulate symbols. The overview of the physical layer is shown in figure 3.1.\n\nPPDU format\nEach physical layer protocol data unit (PPDU) consists of a preamble, PHY header, and the data itself. The process of encoding the whole PPDU can be seen in figure 3.2.\nReed-Solomon encoding is used to encode the physical service data unit (PSDU) of the HRP UWB PHY. It adds redundant symbols to the original message symbols to form a codeword that can be decoded using polynomial interpolation or factorization techniques. Reed-Solomon encoding improves the error-correction performance of the HRP UWB PHY and enables it to handle burst errors or random errors that may occur in the wireless channel 4.\nConvolutional encoding is used to encode the PSDU of the HRP UWB PHY after Reed-Solomon encoding. It uses a finite state machine with memory cells to generate output bits based on the current and previous input bits. It adds parity bits to the original information bits to form a codeword that can be decoded using the Viterbi algorithm or other sequential decoding techniques. Convolutional encoding improves the error correction performance of the HRP UWB PHY and enables it to handle noisy or fading channels.\n\n\n\nFigure 3.2: PPDU encoding process. [1]\n\n\nA preamble in HRP UWB PHY is a sequence of known bits sent at the beginning of each frame. It is used for frame synchronization, channel estimation, and ranging measurements. It consists of two parts: a synchronization header (SHR) 3.3 and a physical layer header (PHR) 3.4.\nThe SHR contains a preamble symbol (SYNC) and a start-of-frame delimiter (SFD). The SFD is a fixed sequence of pulses that indicates the start of a frame. The PS is a burst of UWB pulses that can be modulated by burst position modulation (BPM) or binary phase-shift keying (BPSK). The preamble symbol repetitions (PSR) define the number of repeated sequences, ranging from 16 to 4,096 repetitions.\n\n\n\nFigure 3.3: SHR field structure. [3]\n\n\nThe PHR contains information about the data to be received, including the length of the data and the data rate used to transmit the data. It also contains additional information elements to facilitate ranging information exchange.\n\n\n\nFigure 3.4: PHR field structure. [3]\n\n\n\n\nSymbol structure\n\n\n\nFigure 3.5: Symbol stucture. [3]\n\n\nA symbol is the basic unit of information in the HWP UWB PHY. It consists of a short burst of UWB pulses that lasts for \\(2 \\; \\mathrm{ns}\\) and occupies a bandwidth of 0.5-1.3 GHz. The burst can be placed in one of the two possible burst intervals, and its phase can be inverted or not, as can be seen in Figure 3.5. These two choices allow each symbol to carry two bits of information using burst position modulation (BPM) and binary phase-shift keying (BPSK); an example of the modulation can be found in figure 3.6.\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.6: Example of BPM-BPSK modulation,\n\n\n\nThe burst hopping position is a parameter that determines the time position of the UWB pulses within a burst interval. Scrambling code is a pseudo-random sequence that is applied to the data bits before modulation. It is used to randomize the data bits and reduce the peak-to-average power ratio (PAPR) of the UWB pulses.\nIEEE defines the reference pulse as a root-raised cosine pulse with roll-off factor \\(\\beta = 0.5\\) 3.3.\n\\[         \nr(t) = \\frac{4 \\beta}{\\pi \\sqrt{T_p}} \\frac{\\cos{[(1+ \\beta) \\pi t / T_p]} + \\frac{\\sin{[(1 - \\beta) \\pi t / T_p}]}{4 \\beta(t / T_p)}}{1-(4 \\beta t /  T_p)^2}\n\\tag{3.3}\\]\nThe parameter \\(T_p\\) stands for the duration of the pulse. The duration is defined for each channel by table 3.2.\n\n\nTable 3.2: The duration of the reference pulse for each channel. [1]\n\n\n\n\n\n\n\nChannel number\nPulse duration \\(T_p\\) (ns)\nMain lobe width \\(T_w\\) (ns)\n\n\n\n\n{0:3, 5:6, 8:10, 12:14}\n2.00\n0.5\n\n\n7\n0.92\n0.2\n\n\n{4, 11}\n0.75\n0.2\n\n\n15\n0.74\n0.2\n\n\n\n\nFigure 3.7 further illustrates a waveform of the pulse. However, an actual hardware system cannot fully realize the shape of the reference pulse. Therefore IEEE 802.15.4 constrains the transmitted pulse \\(p(t)\\) by a cross-correlation function 3.4 where \\(E_r\\) is the energy of r(t) and \\(E_p\\) is the energy of p(t).\n\\[\n    \\mathrm{\\phi}(\\tau) = \\frac{1}{\\sqrt{E_r E_p}} Re \\int^{\\infty}_{-\\infty} \\mathrm{r}(t) \\mathrm{p}(t - \\tau) \\mathrm{dt}\n\\tag{3.4}\\]\nFor PHY to be IEEE compliant, the main lobe of the transmitted pulse must have a magnitude of cross correlation \\(|\\phi(\\tau)|\\) at least 0.8, and the magnitude of the sidelobes must not be greater than 0.3.\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.7: Reference pulse of UWB radio."
  },
  {
    "objectID": "chapters/3_uwb.html#ranging-techniques",
    "href": "chapters/3_uwb.html#ranging-techniques",
    "title": "3  Ultra-wide band",
    "section": "3.3 Ranging techniques",
    "text": "3.3 Ranging techniques\n\nTime Difference of Arrival\nTime difference of arrival (TDOA) position estimation is a technique that uses the difference in the arrival times of UWB signals at multiple receivers to estimate the position of a transmitter.\nTDOA position estimation requires at least four receivers and one transmitter for 3D localization. The receivers measure the time of arrival (TOA) of the UWB signals. The TOA measurements are then used to calculate the TDOA values between different pairs of receivers [6].\n\\[\n    \\sqrt{\\mathbf{x_r}^T \\mathbf{\\hat{x}}} - \\sqrt{\\mathbf{x_i}^T \\mathbf{\\hat{x}}} = c(t_r - t_i)\n\\tag{3.5}\\] Where: \\[\n\\begin{aligned}\n    \\mathbf{\\hat{x}} &= \\text{estimated position of the transmitter.} \\\\\n    \\mathbf{x_r} &= \\text{Position of the reference receiver.} \\\\\n    \\mathbf{x_i} &= \\text{Position of receiver \\textit{i}.} \\\\\n    t_r &= \\text{Time of arrival for the reference receiver.} \\\\\n    t_r &= \\text{Time of arrival for the receiver \\textit{i}.} \\\\\n    c &= \\text{Speed of light.} \\\\\n\\end{aligned}\n\\]\nTo estimate the position of the transmitter system of equations 3.5 is solved [4]. The main challenge in implementing TDoA is synchronizing the clock in all receivers [5].\nThe TDoA system can be used in a variety of applications, such as indoor positioning, vehicle or people tracking, and asset tracking. The accuracy of the TDoA system depends on the number and placement of the UWB sensors and the timing resolution of the system.\n\n\nTwo-way ranging\nTwo-way ranging (TWR) is a technique used by UWB systems to estimate the distance between two devices. TWR requires two-way communication between two devices, where one device sends a signal to another device and waits for a response, as shown in figure 3.8. The time difference between the transmission and reception of the signal is used to calculate the distance between the two devices.\n\n\n\nFigure 3.8: Two way ranging with two round trips.\n\n\nSingle-sided two-way ranging (SS-TWR) is a technique where only one device sends a signal and waits for a response from another device. The time difference between the transmission and reception of the signal is used to calculate the distance between the two devices.\n\\[\n    \\mathrm{TOF} = \\frac{R_a - D_b}{2}\n\\] Where: \\[\n\\begin{aligned}\n    \\mathrm{TOF} &= \\text{Time of flight.} \\\\\n    R_a &= \\text{Time of round trip} \\\\\n    D_b &= \\text{Response delay.} \\\\\n\\end{aligned}\n\\]\nDouble-sided two-way ranging (DS-TWR) is a technique where both devices send signals and wait for responses from each other. The time difference between the transmission and reception of signals from both devices is used to calculate the distance between them.\n\\[\n    \\mathrm{TOF} = \\frac{R_a R_b - D_a D_b}{R_a + D_a + R_b + D_b}\n\\]\nThe main advantage of DS-TWR is its ability to compensate for the effect of clock drift [2]. Clock drift refers to several related phenomena where a clock does not run at exactly the same rate as a reference clock. That is, after some time, the clock drifts apart or gradually desynchronizes from the other clock. All clocks are subject to drift, causing eventual divergence unless the are resynchronized. The drift of the clock can be caused by many factors, such as changes in temperature, aging of components, and changes in power supply voltage [2].\n\n\n\n\n\n1. 2011. IEEE standard for local and metropolitan area networks–part 15.4: Low-rate wireless personal area networks (LR-WPANs). IEEE Std 802.15.4-2011 (Revision of IEEE Std 802.15.4-2006): 1–314. https://doi.org/10.1109/IEEESTD.2011.6012487\n\n\n2. 2014. A sources of error in DW1000 based two-way ranging scheme APS011. Decawave; https://www.qorvo.com/products/d/da008446.\n\n\n3. 2016. IEEE standard for low-rate wireless networks. IEEE Std 802.15.4-2015 (Revision of IEEE Std 802.15.4-2011): 1–709. https://doi.org/10.1109/IEEESTD.2016.7460875\n\n\n4. 2021. Object tracking using time difference of arrival. MathWorks; https://www.mathworks.com/help/fusion/ug/object-tracking-using-time-difference-of-arrival.html.\n\n\n5. Yan Xie, Gerard J. M. Janssen, and Alle-Jan van der Veen. 2016. A practical clock synchronization algorithm for UWB positioning systems. In 2016 IEEE international conference on acoustics, speech and signal processing (ICASSP), 3891–3895. https://doi.org/10.1109/ICASSP.2016.7472406\n\n\n6. Wenda Zhao, Abhishek Goudar, and Angela P. Schoellig. 2022. Finding the right place: Sensor placement for UWB time difference of arrival localization in cluttered indoor environments. IEEE Robotics and Automation Letters 7, 3: 6075–6082. https://doi.org/10.1109/LRA.2022.3165181"
  },
  {
    "objectID": "chapters/3_uwb.html#footnotes",
    "href": "chapters/3_uwb.html#footnotes",
    "title": "3  Ultra-wide band",
    "section": "",
    "text": "Apple AirTag https://www.apple.com/airtag/↩︎\nSiemens RTLS https://www.siemens.com/global/en/products/automation/industrial-identification/simatic-rtls.html/↩︎\nSewio real-time location system https://www.sewio.net/↩︎\nMathworks HRP UWB IEEE 802.15.4a/z Waveform Generation https://www.mathworks.com/help/comm/ug/hrp-uwb-ieee-802.15.4az-waveform-generation.html↩︎"
  },
  {
    "objectID": "chapters/4_kalman.html#linear-kalman-filter",
    "href": "chapters/4_kalman.html#linear-kalman-filter",
    "title": "4  Kalman filters",
    "section": "4.1 Linear Kalman filter",
    "text": "4.1 Linear Kalman filter\nA linear Kalman filter is a recursive algorithm that uses the Bode-Shannon representation of random processes and the state-transition method of analysis of dynamic systems to estimate the state of a system from noisy measurements. In the prediction step 4.1, the algorithm uses a state transition matrix to project the current state and its covariance matrix to the next time step.\n\\[\n\\begin{aligned}\n    \\textit{Predict step} \\\\\n    \\hline\n    \\mathbf{\\hat{x}} &= \\mathbf{F x + Bu} \\\\\n    \\mathbf{\\hat{P}} &= \\mathbf{F P F^{T} + Q}\n\\end{aligned}\n\\tag{4.1}\\] Where: \\[\n\\begin{aligned}\n    \\mathbf{\\hat{x}}, \\mathbf{\\hat{P}} &= \\text{State mean and covariance} \\\\\n    \\mathbf{F} &= \\text{Transition matrix} \\\\\n    \\mathbf{Q} &= \\text{Process matrix} \\\\\n    \\mathbf{B, u} &= \\text{Input to the system}\n\\end{aligned}\n\\]\nIn the correction step 4.4, the algorithm uses a measurement matrix to update the predicted state and its covariance matrix with the new measurement. The algorithm optimizes the estimation by minimizing the mean squared error between the true state and the estimated state [1].\n\\[\n\\begin{aligned}\n    \\textit{Update step} \\\\\n    \\hline\n    \\mathbf{y} &= \\mathbf{z - H x} \\\\\n    \\mathbf{K} &= \\mathbf{P H^T (H P H^T + R)^{-1}} \\\\\n    \\mathbf{\\hat{x}} &= \\mathbf{x + K y} \\\\\n    \\mathbf{\\hat{P}} &= \\mathbf{(I - K H)P} \\\\\n\\end{aligned}\n\\tag{4.2}\\] Where: \\[\n\\begin{aligned}\n    \\mathbf{z}, \\mathbf{R} &= \\text{Measurement and convariance} \\\\\n    \\mathbf{H} &= \\text{Measurement function} \\\\\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "chapters/4_kalman.html#extended-kalman-filter",
    "href": "chapters/4_kalman.html#extended-kalman-filter",
    "title": "4  Kalman filters",
    "section": "4.2 Extended Kalman filter",
    "text": "4.2 Extended Kalman filter\nThe Kalman filter is an optimal estimation algorithm that combines measurements from sensors with predictions from a mathematical model to estimate the true state of a system. However, the Kalman filter assumes that both the system dynamics and the measurement model are linear. In real-world applications, many systems exhibit non-linear behavior, and the extended Kalman filter is used to handle such cases.\n\\[\n\\begin{aligned}\n    \\textit{Predict step} \\\\\n    \\hline\n    \\mathbf{F} &= \\frac{\\partial \\mathbfcal{f}(\\mathbf{x_t}, \\mathbf{u_t})}{\\partial \\mathbf{x}}\\bigg\\vert_{\\mathbf{x_t}, \\mathbf{u_t}} \\\\\n    \\mathbf{\\hat{x}} &= \\mathbfcal{f}(\\mathbf{x}, \\mathbf{u}) \\\\\n    \\mathbf{\\hat{P}} &= \\mathbf{F P F^{T} + Q}\n\\end{aligned}\n\\tag{4.3}\\]\nThe extended Kalman filter linearizes the system and measurement models using Taylor series expansions. It uses the first-order derivatives (Jacobian matrices) to linearize the equations \\(f(x)\\) at each time step. The filter then performs the standard Kalman filter prediction and update steps using these linearized models.\n\\[\n\\begin{aligned}\n    \\textit{Update step} \\\\\n    \\hline\n    \\mathbf{H} &= \\frac{\\partial \\mathbfcal{h}(\\mathbf{x_t})}{\\partial \\mathbf{x}}\\bigg\\vert_{\\mathbf{x_t}} \\\\\n    \\mathbf{y} &= \\mathbf{z} - \\mathbfcal{h}(\\mathbf{x}) \\\\\n    \\mathbf{K} &= \\mathbf{P H^T (H P H^T + R)^{-1}} \\\\\n    \\mathbf{\\hat{x}} &= \\mathbf{x + K y} \\\\\n    \\mathbf{\\hat{P}} &= \\mathbf{(I - K H)P} \\\\\n\\end{aligned}\n\\tag{4.4}\\]\nIt’s worth noting that the extended Kalman filter has some limitations. Since it uses linear approximations, it may not perform well for highly non-linear systems or when the linearization is inaccurate [2]. In such cases, other techniques, such as the unscented Kalman filter or particle filters, may be more appropriate."
  },
  {
    "objectID": "chapters/4_kalman.html#unscented-kalman-filter",
    "href": "chapters/4_kalman.html#unscented-kalman-filter",
    "title": "4  Kalman filters",
    "section": "4.3 Unscented Kalman filter",
    "text": "4.3 Unscented Kalman filter\nThe unscented Kalman filter (UKF) is a technique for nonlinear estimation that uses a deterministic sampling approach to propagate a Gaussian random variable through system dynamics [6]. The UKF employs the unscented transform (UT), which generates a set of sample points that capture the mean and covariance of the original distribution.\nThe unscented transform is a technique for approximating the outcome of applying a nonlinear function to a probability distribution that is described by a mean and a covariance matrix. It does this by choosing a set of points, known as sigma points Figure 4.1.\n\n\n\nFigure 4.1: Comparsion between sampling, EKF and sigma points. [4]\n\n\nMerwe describes generating the sigma points in the paper The unscented Kalman filter for nonlinear estimation[6]. These sigma points are chosen to capture the mean and covariance of the current estimated state and are transformed through the non-linear model to predict the state at the next time step. The sigma points \\(\\mathbfcal{X}_i\\) as well as the weights \\(\\omega_i\\) for each point are calculated using equation 4.5. The weights \\(\\omega_i\\) must follow the equation \\(\\sum_{i=0}^{2L} \\omega_i = 1\\). \\[\n\\lambda = \\alpha^2 (L + \\kappa) - L\n\\] \\[\n\\begin{aligned}\n    \\mathbfcal{X_0} &= \\hat{x}   &  \\omega^{m}_0 &= \\frac{\\lambda}{L + \\lambda} & i &= 0  \\\\\n    \\mathbfcal{X_i} &= \\hat{x} + \\left( \\sqrt{(L+\\lambda) \\mathbf{P_x}} \\right)_i   &  \\omega^{c}_i &= \\frac{1}{2(L + \\lambda)} + (1 − \\alpha^2 + \\beta) & i &= 1,..., L \\\\\n    \\mathbfcal{X_i} &= \\hat{x} - \\left( \\sqrt{(L+\\lambda) \\mathbf{P_x}} \\right)_i & \\omega^{m}_i &= \\omega^{c}_i = \\frac{1}{2(L +\\lambda)} & i &= L+1,...,2L\n\\end{aligned}\n\\tag{4.5}\\] Where: \\[\\begin{gathered}\n\\begin{align*}\n    \\mathbf{\\hat{x}}, \\mathbf{P_x} &= \\text{State vector and covariance} \\\\\n    L &= \\text{Dimension of state vector}\n\\end{align*}\n\\\\\n0 \\leq \\alpha \\leq 1 \\\\\n0 \\leq \\kappa \\\\\n0 \\leq \\beta\n\\end{gathered}\\]\nThe sigma points are used both in the predict step 4.6 and update step 4.7 and need to be regenerated for each new measurement. Instead of the matrix \\(\\mathbf{F}\\) 4.1 and \\(\\mathbf{H}\\) 4.4 known from LKF, the UKF is provided with non-linear functions \\(\\mathbf{f(} \\mathbfcal{X} \\mathbf{)}\\) and \\(\\mathbf{h(} \\mathbfcal{X} \\mathbf{)}\\).\n\\[\n\\begin{gathered}\n    \\textit{Predict step} \\\\\n    \\hline\n    \\mathbfcal{Y} = \\mathbfcal{f}( \\mathbfcal{X} \\mathbf{)} \\\\\n    \\mathbf{\\hat{x}} = \\sum_{i=0}^{2L} \\omega^m_i \\mathbfcal{Y}_i \\quad\\quad\n    \\mathbf{\\hat{P}} = \\sum_{i=0}^{2L} \\omega^c_i (\\mathbfcal{Y}_i - \\mathbf{x})(\\mathbfcal{Y}_i - \\mathbf{x})^T + \\mathbf{Q}\n\\end{gathered}\n\\tag{4.6}\\]\nBy comparing the predicted measurements with the actual measurements, the UKF computes the Kalman gain, which determines the optimal blend between the predicted state and the measurement updates. Finally, the updated state estimate is obtained by incorporating the measurement information into the predicted state estimate using the Kalman gain. The update step of the UKF enables the filter to adaptively adjust the state estimate based on the measurements, providing a more accurate estimation of the true state of the system.\n\\[\n\\begin{gathered}\n    \\textit{Update step} \\\\\n    \\hline\n    \\mathbfcal{Z} = \\mathbf{h(} \\mathbfcal{X} \\mathbf{)} \\\\\n    \\mathbf{\\mu}_z = \\sum_{i=0}^{2L} \\omega^m_i \\mathbfcal{Z}_i \\quad\\quad\n    \\mathbf{P}_z = \\sum_{i=0}^{2L} \\omega^c_i (\\mathbfcal{Z}_i - \\mathbf{\\mu}_z)(\\mathbfcal{Z}_i - \\mathbf{\\mu}_z)^T + \\mathbf{R} \\\\\n    \\mathbf{y} = \\mathbf{z} - \\mathbf{\\mu}_z \\qquad \\mathbf{P}_{xz} = \\sum_{i=0}^{2L} \\omega_i^c (\\mathbfcal{X}_i - \\mathbf{x}) (\\mathbfcal{Z}_i - \\mathbf{\\mu}_z)^T \\\\\n    \\mathbf{K} = \\mathbf{P}_{xz} \\mathbf{P}_z^{-1} \\\\\n    \\mathbf{\\hat{x}} = \\mathbf{x} + \\mathbf{K} \\mathbf{y} \\qquad \\mathbf{\\hat{P}} = \\mathbf{P} - \\mathbf{K} \\mathbf{P}_z \\mathbf{K}^T\n\\end{gathered}\n\\tag{4.7}\\]\nThe UKF has been shown to achieve higher accuracy and robustness than the extended Kalman filter (EKF) for various non-linear estimation problems, such as state estimation, parameter estimation, and dual estimation [6].\n\n\n\n\n\n1. R. E. Kalman. 1960. A New Approach to Linear Filtering and Prediction Problems. Journal of Basic Engineering 82, 1: 35–45. https://doi.org/10.1115/1.3662552\n\n\n2. Roger Labbe. 2014. Kalman and bayesian filters in python. GitHub repository.\n\n\n3. Priya Shree Madhukar and L. B. Prasad. 2020. State estimation using extended kalman filter and unscented kalman filter. In 2020 international conference on emerging trends in communication, control and computing (ICONC3), 1–4. https://doi.org/10.1109/ICONC345789.2020.9117536\n\n\n4. Rudolph Merwe and Eric Wan. 2003. Sigma-point kalman filters for probabilistic inference in dynamic state-space models. Proceedings of the Workshop on Advances in Machine Learning.\n\n\n5. M. St-Pierre and D. Gingras. 2004. Comparison between the unscented kalman filter and the extended kalman filter for the position estimation module of an integrated navigation information system. In IEEE intelligent vehicles symposium, 2004, 831–835. https://doi.org/10.1109/IVS.2004.1336492\n\n\n6. E. A. Wan and R. Van Der Merwe. 2000. The unscented kalman filter for nonlinear estimation. In Proceedings of the IEEE 2000 adaptive systems for signal processing, communications, and control symposium (cat. no.00EX373), 153–158. https://doi.org/10.1109/ASSPCC.2000.882463"
  },
  {
    "objectID": "chapters/5_implementation.html#qorvo-dw1000-uwb-phy-radio",
    "href": "chapters/5_implementation.html#qorvo-dw1000-uwb-phy-radio",
    "title": "5  UAV implementation",
    "section": "5.1 Qorvo DW1000 UWB PHY radio",
    "text": "5.1 Qorvo DW1000 UWB PHY radio\nQorvo DW1000 is a UWB PHY radio developed and manufactured by Qorvo2. The proposed solution utilizes a Qorvo DWM1001-DEV development board which consists of a DWM1001C transceiver module and a J-Link debug probe. Figure 5.2 showcases the printed circuit board (PCB) of the Qorvo DWM1001-DEV. The DWM1001C houses the DW1000 radio chip, nRF52832 microcontroller, 3.0 V, and 1.8 V power supplies. The DW1000 is connected to the nRF52832 via the SPI bus. The module also includes Bluetooth connectivity and an accelerometer, but it remained unutilized.\n\n\n\nFigure 5.2: Qorvo DWM1001 development board.\n\n\nThe nRF52832 is the microcontroller that gets programmed. The programming language of choice is C++ with combination of Zephyr RTOS3 which enables use of multitasking and concurrency. Zephyr RTOS also contains a rich selection of peripheral drivers for faster development and higher abstraction.\nA ranging technique of choice is double-sided two-way ranging. It fulfills all the needs, as it compensates for clock drift and does not require any infrastructure. Each of the two devices in the ranging instance fills out fields in the ranging message 5.3. The values in the ranging message are referenced to DW1000 clock frequency. Therefore, in order to get an actual time, the values need to be multiplied by \\(15.65 \\textrm{ ps}\\).\n\n\n\nFigure 5.3: Structure of ranging message. Numbers denote bytes.\n\n\nData from UWB are sent to ROS via UART connection at baud rate 115200. As a communication protocol, the Baca Protocol is used as recommended by the MRS group4.\nUWB ranging on the ROS side handles uwb_range_node. The node decodes the messages and republishes them as ROS topics. Every N seconds, the node sends a beacon message through the UWB. This message is then received and processed by other UAVs. An essential function of the beacon message is to synchronize the UWB measurements with UVDAR measurements, enabling the fusion of the measurements based on IDs. This is done via the UAV identificator that is embedded in the beacon message. The retrieved ID fromthe beacon message is assigned to the MAC addresses in the address resolution table."
  },
  {
    "objectID": "chapters/5_implementation.html#object-tracker",
    "href": "chapters/5_implementation.html#object-tracker",
    "title": "5  UAV implementation",
    "section": "5.2 Object tracker",
    "text": "5.2 Object tracker\nAn object tracker is an ROS node where the measurements are fused. Both linear and unscented Kalman filters are utilized in this node, as can be seen in figure 5.4. The fuse proceeds in the world frame to negate the effects of ego-motion.\n\n\n\nFigure 5.4: Fuse of UVDAR and UWB measurements using Kalman filters.\n\n\nFor the predict step, an implementation from LKF is used with the state vector and transition matrix described by equations 5.1. \\[\n\\begin{aligned}\n    \\mathbf{x} &= \\begin{bmatrix} x & y & z & roll & pitch & yaw \\end{bmatrix}^{T} \\\\ \\\\\n    \\mathbf{F} &= \\begin{bmatrix}\n    1 & 0 & 0 & 0 & 0 & 0 \\\\\n    0 & 1 & 0 & 0 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 & 0 & 0 \\\\\n    0 & 0 & 0 & 1 & 0 & 0 \\\\\n    0 & 0 & 0 & 0 & 1 & 0 \\\\\n    0 & 0 & 0 & 0 & 0 & 1 \\\\\n    \\end{bmatrix}\n\\end{aligned}\n\\tag{5.1}\\] Figure 5.5 depicts the challenge of integrating UWB and UVDAR.\n\n\n\nFigure 5.5: Situational schema of data fusion.\n\n\nThe UVDAR measurement consists of a position described by Cartesian coordinates and orientation described by a quaternion as shown in 5.2 with a corresponding covariance matrix. The measurement is in the frame of the camera, but with help of mrs_transformer the coordinates are transformed to the world coordinates. \\[\n\\begin{aligned}\n   \\mathrm{position} = \\begin{bmatrix} x & y & z \\end{bmatrix}^T \\qquad \\mathrm{orientation} = \\begin{bmatrix} x & y & z & w \\end{bmatrix}^T\n\\end{aligned}\n\\tag{5.2}\\] For this kind of measurement, the linear Kalman filter is the best choice, because there are no nonlinearity functions and the computation cost is low. The rotation from UVDAR is transformed from quaternion to Euler angles. A measurement matrix \\(\\mathbf{H}\\) is a simple identity matrix of dimension six.\nThe UWB measurement acquires the distance from UAV \\(\\mathbf{x_1}\\) to UAV \\(\\mathbf{x_2}\\) as noted in equation 5.3. \\[\n\\begin{aligned}\n    UWB_{distance} &= \\sqrt{(\\mathbf{x_2 - x_1})^T (\\mathbf{x_2 - x_1})}\n\\end{aligned}\n\\tag{5.3}\\] The problem is non-linear and requires a more complex approach. For this reason, the unscented Kalman filter is employed for fusing distance. The previous state needs to be transformed from world frame to UAV frame. The result needs to be transformed back to world frame back to world. The measurement function is described as a C++ function 5.6.\n\n\n\n\nkalman::range_ukf_t::z_t observe_ukf(\n            const kalman::range_ukf_t::x_t &x)\n{\n    Eigen::VectorXd pose(3);\n\n    pose &lt;&lt; x[(int)STATE::X], \n                x[(int)STATE::Y], \n                x[(int)STATE::Z];\n    kalman::range_ukf_t::z_t z;\n\n    z &lt;&lt; pose.norm();\n    return z;\n}\n\n\nFigure 5.6: Measurement function for fusing distance."
  },
  {
    "objectID": "chapters/5_implementation.html#footnotes",
    "href": "chapters/5_implementation.html#footnotes",
    "title": "5  UAV implementation",
    "section": "",
    "text": "ROS Noetic release info http://wiki.ros.org/noetic↩︎\nQorvo DW1000 https://www.qorvo.com/products/p/DW1000↩︎\nZephyr RTOS https://zephyrproject.org/↩︎\nBaca protocol https://github.com/ctu-mrs/mrs_serial↩︎"
  },
  {
    "objectID": "chapters/6_experiments.html#ultra-wide-band-experiments",
    "href": "chapters/6_experiments.html#ultra-wide-band-experiments",
    "title": "6  Simulations and real-world experiments",
    "section": "6.1 Ultra-wide band experiments",
    "text": "6.1 Ultra-wide band experiments\n\nLine segment test\nThis experiment aims to test the maximum range and obtain a transfer characteristic of the sensor. The purpose of the first UAV was to act as an observer and, for the duration of the test remained at position \\(\\begin{bmatrix}0 & 0 & 5\\end{bmatrix}^T\\). The econd UAV was flying on a trajectory predefined by the parametric equation 6.1.\n\\[\n    \\mathbf{position}(t) = \\begin{bmatrix} 0 \\\\ 65 + 55 \\sin (2 \\pi t) \\\\ 5 \\end{bmatrix}, \\quad t \\in \\left(0, 1\\right)\n\\tag{6.1}\\]\n\n\nCircular trajectory\nAs noted above, the results from the UWB should be the same for all orientations. To test whether that is a correct assumption, 4 experiments have been conducted. In each test, one UAV acted as an observer and stayed at position \\(\\begin{bmatrix}0 & 0 & 5\\end{bmatrix}^T\\). The second UAV followed a circle of radius 10 m around the first UAV in a car-like motion. The difference between the 4 experiments was the relative angle to the velocity vector.\n\n\nResults\nAll proposed experiments regarding the UWB were successfully conducted. Results from the first experiment in Figure 6.2 showed that the UWB measurements are indeed precise and do not express any signs of nonlinearity. The maximum range of 120 m was reached by UWB, however, the measurements at the far end are not reliable and often drop out.\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6.2: Transfer characteristic of UWB.\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6.3: Trajectory plotted in time with error.\n\n\n\nAs Figure 6.4 shows, the measurement error is dependent on the angle. In A sources of error in DW1000 [1] the manufacturer mentions that there are two sources of error, clock drift and received signal level. The implemented ranging technique (double-sided two-way ranging) compensates for clock drift. Therefore, the only error source left is the received signal level. The more powerful the signal, the sooner it is timestamped, leading to a shorter distance reported. This error could be easily corrected by constructing correction function \\(f(\\mathrm{dB})\\). Unfortunately, the received signal level was not recorded. Further research should be done to correct errors dependent on the level of the received signal.\nResults and ranging multiple static responders with UWB is demonstrated in Appendix C.\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6.4: Comparison between different radiation angles."
  },
  {
    "objectID": "chapters/6_experiments.html#uvdar-and-uwb-fusion-experiments",
    "href": "chapters/6_experiments.html#uvdar-and-uwb-fusion-experiments",
    "title": "6  Simulations and real-world experiments",
    "section": "6.2 UVDAR and UWB fusion experiments",
    "text": "6.2 UVDAR and UWB fusion experiments\n\nLeader follower algorithm\nTo test the fusion of UVDAR and UWB in loop, a leader-follower algorithm was used. In this test, a leader UAV flies a pre-planned trajectory. A follower UAV tries to follow the leader based only on UVDAR and UWB sensor fusion. The algorithm was inspired by the UVDAR System for Visual Relative Localization With Application to Leader–Follower Formations of Multirotor UAVs [2] and is represented in figure 6.5.\n\n\n\nFigure 6.5: Visual representation of the leader-follower algorithm.\n\n\n\n\nResults\nUnfortunately, due to an incorrect configuration of the experiment, the test has not been successfully conducted in real-life. A simulated test using the Gazebo simulator1 was conducted as an alternative approach. A special node was made to simulate results from UWB, the node calculates a distance between UAVs from ground truth and then adds noise with distribution \\(\\mathcal{N}(0, 0.05)\\). The test was repeated two times. First, the UWB and UVDAR fusion was kept for the whole time, providing an accurate position of the leader UAV. During the second test, the fusion process was halted mid-way and only UVDAR measurements were utilized.\nThe results depicted in Figure 6.6 demonstrate the advantages of fusing the UWB and UVDAR technologies. Due to the absence of precise distance measurements from UWB (Ultra-Wideband) technology, the follower UAV could not maintain track of the leader UAV.\nMore simulated tests of the Object tracker can be seen in Appendix C.\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6.6: Leader-follower algorithm results.\n\n\n\n\n\n\n\n\n1. 2014. A sources of error in DW1000 based two-way ranging scheme APS011. Decawave; https://www.qorvo.com/products/d/da008446.\n\n\n2. Viktor Walter, Nicolas Staub, Antonio Franchi, and Martin Saska. 2019. UVDAR system for visual relative localization with application to leader–follower formations of multirotor UAVs. IEEE Robotics and Automation Letters 4, 3: 2637–2644. https://doi.org/10.1109/LRA.2019.2901683"
  },
  {
    "objectID": "chapters/6_experiments.html#footnotes",
    "href": "chapters/6_experiments.html#footnotes",
    "title": "6  Simulations and real-world experiments",
    "section": "",
    "text": "Gazebo simulator https://gazebosim.org/home↩︎"
  },
  {
    "objectID": "chapters/7_conclusion.html",
    "href": "chapters/7_conclusion.html",
    "title": "7  Conclusion",
    "section": "",
    "text": "In conclusion, this thesis has made significant contributions to the enhancement of visual relative mutual localization systems, particularly in the context of UAV swarms. The primary focus was to improve accuracy and reliability by integrating Ultra-wide band (UWB) technology for distance measurements.\nThe proposed solution utilized the Qorvo DWM1000 UWB radio as a means of acquiring distance measurements. By leveraging the mathematical framework of Kalman filters, the fusion of UVDAR and UWB data was achieved. This fusion approach has demonstrated its versatility, as it can be applied not only to mutual localization within UAV swarms but also to localize unmanned ground vehicles (UGVs) or serve as a navigation beacon for landing platforms.\nAlthough the current implementation of UWB has shown reliable performance, there is room for further improvement. Future work should focus on refining the UWB implementation to correct errors caused by variations in received signal levels. Additionally, the utilization of advanced UWB radios with 3D localization capabilities, employing antenna arrays, could enable the deployment of redundant systems onboard UAVs, further enhancing accuracy and robustness.\nThe results of this thesis have contributed significantly to the ecosystem of the MRS group, providing researchers with a high-precision relative mutual localization system. By extending the boundaries of what is possible, this system opens up new avenues for research and exploration in various domains.\nThe developed system holds immense potential for a wide range of applications, from collaborative tasks and swarm coordination in UAV swarms to autonomous navigation and precise landing capabilities. The integration of UVDAR and UWB technology has paved the way for advancements in the field, enabling researchers to push the boundaries of what can be achieved with UAV swarms and other autonomous systems.\nIn conclusion, this thesis has successfully addressed the challenges associated with visual relative mutual localization in UAV swarms by integrating UWB technology. The proposed fusion approach and its future potential have made valuable contributions to the field, providing researchers with the means to expand the possibilities of UAV swarm applications.\n\n\n\n\n\n\n\n\n  \n\n\n\n\nKalman filters\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nReferences\n\n\n\n\n\n\n\n\n\n\n\n\nMay 22, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nSimulations and real-world experiments\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nSource code\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUAV implementation\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-violet Direction and Ranging\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-wide band\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "chapters/references.html",
    "href": "chapters/references.html",
    "title": "References",
    "section": "",
    "text": "1. 2011. IEEE standard for local and metropolitan\narea networks–part 15.4: Low-rate wireless personal area networks\n(LR-WPANs). IEEE Std 802.15.4-2011 (Revision of IEEE Std\n802.15.4-2006): 1–314. https://doi.org/10.1109/IEEESTD.2011.6012487\n\n\n2. 2014. A sources of error in DW1000 based\ntwo-way ranging scheme APS011. Decawave; https://www.qorvo.com/products/d/da008446.\n\n\n3. 2016. IEEE standard for low-rate wireless\nnetworks. IEEE Std 802.15.4-2015 (Revision of IEEE Std\n802.15.4-2011): 1–709. https://doi.org/10.1109/IEEESTD.2016.7460875\n\n\n4. 2021. Object tracking using time difference\nof arrival. MathWorks; https://www.mathworks.com/help/fusion/ug/object-tracking-using-time-difference-of-arrival.html.\n\n\n5. R.\nE. Kalman. 1960. A New Approach to Linear Filtering\nand Prediction Problems. Journal of Basic Engineering\n82, 1: 35–45. https://doi.org/10.1115/1.3662552\n\n\n6. Roger Labbe. 2014. Kalman and bayesian filters\nin python. GitHub repository.\n\n\n7. Priya Shree Madhukar and L. B. Prasad. 2020.\nState estimation using extended kalman filter and unscented kalman\nfilter. In 2020 international conference on emerging trends in\ncommunication, control and computing (ICONC3), 1–4. https://doi.org/10.1109/ICONC345789.2020.9117536\n\n\n8. Rudolph Merwe and Eric Wan. 2003. Sigma-point\nkalman filters for probabilistic inference in dynamic state-space\nmodels. Proceedings of the Workshop on Advances in Machine\nLearning.\n\n\n9. Matej Petrlik, Pavel Petracek, Vit Kratky,\nTomas Musil, Yurii Stasinchuk, Matous Vrba, Tomas Baca, Daniel Hert,\nMartin Pecka, Tomas Svoboda, and Martin Saska. 2023. UAVs Beneath the Surface: Cooperative Autonomy for\nSubterranean Search and Rescue in DARPA SubT. Field\nRobotics 3: 1–68. https://doi.org/https://doi.org/10.55417/fr.2023001\n\n\n10. E.\nRosten and T. Drummond. 2005. Fusing points and lines for high\nperformance tracking. In Tenth IEEE international conference on\ncomputer vision (ICCV’05) volume 1, 1508–1515 Vol. 2. https://doi.org/10.1109/ICCV.2005.104\n\n\n11. M.\nSt-Pierre and D. Gingras. 2004. Comparison between the unscented kalman\nfilter and the extended kalman filter for the position estimation module\nof an integrated navigation information system. In IEEE intelligent\nvehicles symposium, 2004, 831–835. https://doi.org/10.1109/IVS.2004.1336492\n\n\n12. G.\nVásárhelyi, Cs. Virágh, G. Somorjai, N. Tarcai, T. Szörenyi, T. Nepusz,\nand T. Vicsek. 2014. Outdoor flocking and formation flight with\nautonomous aerial robots. In 2014 IEEE/RSJ international conference\non intelligent robots and systems, 3866–3873. https://doi.org/10.1109/IROS.2014.6943105\n\n\n13. Viktor Walter, Nicolas Staub, Antonio Franchi,\nand Martin Saska. 2019. UVDAR system for visual relative localization\nwith application to leader–follower formations of multirotor UAVs.\nIEEE Robotics and Automation Letters 4, 3: 2637–2644. https://doi.org/10.1109/LRA.2019.2901683\n\n\n14. V.\nWalter, N.Staub, M. Saska, and A. Franchi. 2018. Mutual localization of\nUAVs based on blinking ultraviolet markers and 3D time-position hough\ntransform. In 14th IEEE international conference on automation\nscience and engineering (CASE 2018).\n\n\n15. V.\nWalter, M. Saska, and A. Franchi. 2018. Fast mutual relative\nlocalization of uavs using ultraviolet led markers. In 2018\ninternational conference on unmanned aircraft system (ICUAS\n2018).\n\n\n16. E.\nA. Wan and R. Van Der Merwe. 2000. The unscented kalman filter for\nnonlinear estimation. In Proceedings of the IEEE 2000 adaptive\nsystems for signal processing, communications, and control symposium\n(cat. no.00EX373), 153–158. https://doi.org/10.1109/ASSPCC.2000.882463\n\n\n17. Yan\nXie, Gerard J. M. Janssen, and Alle-Jan van der Veen. 2016. A practical\nclock synchronization algorithm for UWB positioning systems. In 2016\nIEEE international conference on acoustics, speech and signal processing\n(ICASSP), 3891–3895. https://doi.org/10.1109/ICASSP.2016.7472406\n\n\n18. Wenda Zhao, Abhishek Goudar, and Angela P.\nSchoellig. 2022. Finding the right place: Sensor placement for UWB time\ndifference of arrival localization in cluttered indoor environments.\nIEEE Robotics and Automation Letters 7, 3: 6075–6082. https://doi.org/10.1109/LRA.2022.3165181\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nConclusion\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nKalman filters\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nSimulations and real-world experiments\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nSource code\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUAV implementation\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-violet Direction and Ranging\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-wide band\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "chapters/appendix.html",
    "href": "chapters/appendix.html",
    "title": "Source code",
    "section": "",
    "text": "The attached zip file contains all the source codes, which can also be found in a GitHub repository.\nList of source codes:\n\nleader-follower\nROS node that implements the leader-follower algorithm.\nObject-tracker-ROS\nROS node for UWB and UVDAR data fusion. Could be used for other types of position/distance sensors as well.\nUWB_MRS_ranging_ros_node\nROS node for communication with DWM1001-DEV.\nUWB-MRS-ranging\nZephyr RTOS application for DWM1001. The nRF Connect SDK is needed for compilation and flashing.\nUWB-workspace\nComplete ROS Noetic workspace for UWB. Includes all necessary packages with real-world tmux scripts and gazebo simulations.\n\nThe source code for the thesis is at https://github.com/vitpetrik/UWB-thesis and can be viewed as a web page at https://vitpetrik.github.io/UWB-thesis/.\nAll the source codes are tested on Ubuntu 20.04 and should compile right away. In case of any trouble, feel free to contact the author of this thesis at petrivi2@fel.cvut.cz, vit.petrik@gmail.com, or GitHub.\n\nISO-OSI network model\n\n\n\nFigure 1: OSI-ISO network model.\n\n\n\n\nObject tracker and UWB evaluation tests\nMultiple tests were run to evaluate the function of the Object tracker. As a test environment, the Gazebo simulator was used. The first UAV, an observer, remained at the coordinates \\(\\begin{bmatrix} 0 & 0 & 5 \\end{bmatrix}^T\\) for the entire duration of the tests. The second UAV, a performer, followed a pre-planned trajectory.\nRange error is the difference between the ground truth distance between the UAVs and the distance calculated via unscented transform from Object tracker pose estimation.\n\n\n\nScreenshot from Gazebo simulator showing the two UAVs.\n\n\n\n\n\nCircle path with UWB fusion.\n\n\n\n\n\nCircle path with standalone UVDAR.\n\n\n\n\n\nSquare path with UWB fusion.\n\n\n\n\n\nSquare path with UWB fusion.\n\n\n\n\n\nFlower path with UWB fusion.\n\n\n\n\n\nFlower path with standalone UVDAR.\n\n\n\n\n\nFigure 2: Test of not moving UWBs.\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nConclusion\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nKalman filters\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nReferences\n\n\n\n\n\n\n\n\n\n\n\n\nMay 22, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nSimulations and real-world experiments\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUAV implementation\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-violet Direction and Ranging\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\n  \n\n\n\n\nUltra-wide band\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nVit Petrik\n\n\n\n\n\n\nNo matching items"
  }
]